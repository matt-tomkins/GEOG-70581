[["index.html", "Chapter 1 Introduction 1.1 Practical outline 1.2 Objectives", " Hydrological analysis in R Chapter 1 Introduction 1.1 Practical outline In this set of practicals, well be using R, RStudio and WhiteboxTools to perform hydrological analysis. In Chapters 2 and 3, well install and get to grips with the required programs. In Practical 1 (Chapters 4 - 6), which uses data for the Eskdale watershed, well introduce you to some of the key approaches, including DEM pre-processing, calculating flow parameters and comparing flow algorithms. In Practical 2 (Chapters 7 - X), well utilise these approaches to investigate the water quality of the Mersey Basin. This forms the basis for your assessment. 1.2 Objectives After completing these practicals, you will: have gained experience with new tools (e.g. R, RStudio, WhiteboxTools); become familiar with hydrological approaches used to simulate overland flow from digital elevation models (DEMs); utilised statistical analysis to investigate the relationships between water quality indicators and catchment characteristics; improved your understanding of the hydrological processes influencing water quality. "],["Installation.html", "Chapter 2 Installation 2.1 R 2.2 R Studio 2.3 Course materials", " Chapter 2 Installation During this practical you will be using WhiteboxTools, an open-source GIS software package for hydro-geomorphic applications. While it contains much of the functionality found in a standard GIS software package, it also includes novel functionality specific to hydrological analysis. The tools are also computationally efficient (i.e. fast!), taking advantage of parallel processing and other advancements in computing power. Finally, the tools are developed for cross-platform use, so can be accessed through code (e.g. R, Python) or other GUIs (e.g. QGIS, ArcGIS) if required. To run WhiteboxTools functions (WBT), well be using R as a front-end interface. This will allow us to access and run all of the relevant hydrological functions from WBT, while utilising the statistical and visualisation capabilities of R. 2.1 R To Install R: Open an internet browser and go to https://www.r-project.org/. Click the download R link in the middle of the page under Getting Started. Select a CRAN location (a mirror site) and click the corresponding link e.g. the site provided by Imperial College London. Click on the Download R for Windows link, or the relevant link for your operating system (macOS, Linux). Click on base and then Download R [Version Number] for Windows. The current version is 4.1.1. Once downloaded, double click the application file (.exe) and follow the installation instructions. 2.2 R Studio While R is now installed, it is good practice to use an integrated development environment (IDE) to access and run R functions. The most well known IDE for R is RStudio, which includes a console, higher quality graphics, as well as tools for plotting, history, debugging and workspace management. Note: R may be used without RStudio, but RStudio cannot be used without R. To Install RStudio: Go to https://www.rstudio.com/products/rstudio/download/ and click on Download RStudio for Windows. Installers for macOS and other operating systems are available below. Once downloaded, double click the application file (.exe) and follow the installation instructions. 2.3 Course materials All the data required for this sets of practicals is available on Blackboard or can be downloaded here. "],["Intro_to_R.html", "Chapter 3 A (brief) introduction to R 3.1 Overview 3.2 Loading R 3.3 Variables 3.4 Data structures 3.5 Scripts 3.6 Loading packages 3.7 Loading data 3.8 Plotting", " Chapter 3 A (brief) introduction to R 3.1 Overview 3.1.1 What is R? R was originally focused on statistical data analysis, but has evolved into a general-purpose high level programming language. High level languages are typically less complicated and more user friendly than low level languages (e.g. C, C++, Java), but this comes at the expense of being slightly slower to execute. Importantly, R is free and open-source and its core functionality can be extended using packages. These are available through the Comprehensive R Archive Network (CRAN) and allow the user to perform a range of both simple and complex tasks (e.g. reading and writing files, rendering images), without the requirement to delve into the underlying source code. While there are a myriad of free online resources available to help you learn R, including R for Data Science and YaRrr! The Pirates Guide to R, as well as paid options from Data Camp, this chapter and the subsequent practicals will equip you with all the skills required to complete the course. 3.1.2 Why code? For those of you familiar with desktop GIS (e.g. ArcGIS, QGIS) or other statistical programs (e.g. Excel, SPSS), the transition to using code can be a frightening experience! However, there are a several reasons why it is worth persevering with. First, and with career progression in mind, the ability to code is becoming increasingly important, particularly for those of you who want to progress down GIS or environmental career paths. Getting to grips with R and understanding the fundamentals of coding will equip you to learn new skills and new coding languages which may be required by a future employer (e.g. Python, MATLAB, Julia, Ruby, ). Second, performing your analysis using code ensures that your outputs are reproducible. If you provide someone else with the original data files and the corresponding code i.e. a list of operations carried out by the computer (e.g. read data, modify, plot, perform statistical test, save), they should be able to reproduce your outputs exactly. Third, code is repeatable. In standard GIS software (for example), most functions allow you to perform a single task on a single data file e.g. clipping a digital elevation model to the geometry of a shapefile. By comparison, if that same functionality can be implemented in code, it can applied as easily to 10 data files, or 1000, or 10,000. Finally, code is easily modifiable. Code can be tweaked, adapted, or completely rewritten to produce the desired outputs. In R, a wide range of functions are already available in packages, but you can write your own functions or combine existing functions to suit your analysis. This functionality is often not the case in other software, which are more complicated to modify and typically provide Black Box solutions, where we can inspect the inputs and outputs, but typically have limited understanding of the steps in between. Black Box programming 3.1.3 A quick note on the practicals As we progress through this course, make sure to read the content carefully. However, you do not have to run every bit of code in this document, although have a go where you feel it would help your understanding. If I explicitly want you to do something, I will write an instruction that looks like this: This is an instruction that tells you something to either think about, or do. 3.1.4 Dealing with errors Before we load R and take our first steps towards coding excellence, it is worth noting that errors are an inevitable aspect of coding. Irrespective of how good you are, you will spend more time fixing your code (i.e. debugging) than writing it! Luckily, when R encounters an error, it will try and help you out. For example, shown below is some simple R code. Here, we are tying to create a new variable called a, which is the product (+) of variable b and the number 1: a &lt;- b + 1 ## Error in eval(expr, envir, enclos): object &#39;b&#39; not found In this example, the code fails and prints the error message object 'b' not found because the variable b does not exist! We could solve this by defining b beforehand as follows: b &lt;- 3 a &lt;- b + 1 a ## [1] 4 These error messages are important and contain helpful information - do not ignore them! If youve struggled to resolve the problem, you should then Google it (normally by just typing R followed by the error message into Google), e.g. R Error in eval(expr, envir, enclos): object 'b' not found. Another useful source of information is StackOverflow which is a public collection of coding questions and answers. If youve come across a challenging error, theres a high probability that someone else has also encountered the same error, and there may be a solution already available. Understanding, interpreting and fixing error messages is a key programming skill, so read the error messages carefully and use the above resources (Google, StackOverflow). If you need any additional help, staff and TAs will be happy to help during the practicals. 3.2 Loading R Now that we understand what R is, why its useful and what to do when something goes wrong, lets begin. Open RStudio. The RStudio user-interface should resemble the following: This contains the following primary windows, which are described below: In the console window, commands can be typed and results returned. For example, typing the following command into the console: 1 + 2 produces: ## [1] 3 Copy and paste the above code into the console and press Enter to run. Does it produce the correct result? In the Workspace window, you can see all the objects that you have created in the current R session (Environment tab; currently empty!) as well as a record of the commands youve used (History tab; 1 + 2). At its most basic, R can operate as a powerful calculator. We can add +, subtract -, multiply * and divide /, take the exponent ^, calculate the square root sqrt() or the logarithm of a number log10(), or melt our computers by using the factorial() function. We can also combine operators to produce more complicated commands. For example, the following code takes the sqrt() of 25 and then takes its factorial (\\(5!\\)), which is equal to \\(5 * 4 * 3 * 3 * 1\\). factorial(sqrt(25)) ## [1] 120 3.3 Variables One of the most important things to know about in R is the variable or object. In this set of practicals, we use the term variable, which is more common across different programming languages. Variables are containers that you can store values in, and then refer to again later. R creates variables for you automatically, so all that is required is to name it and then use the assignment operator &lt;- to assign a value to it. As a general rule (and because of complicated reasons), use &lt;- for assignment, as shown below, and dont use =: b &lt;- 3 Run the above code. This assigns the value of 3 to a variable named b: You should now see that under the Workspace window, the variable b has been added to the Environment tab: The variable b can now be called again by the user. Run the following in the console. Does it work as expected? b + 5 There are number of benefits to using variables. For example, take the following: a &lt;- 5 b &lt;- 10 result &lt;- (sqrt(a) + log(b))^a + 2*b result ## [1] 1945.905 This is a relatively complicated mathematical formula! It uses a square root sqrt() and logarithm log() function, as well as multiplication * and powers ^. We could replicate this result by substituting each value of a for 5 and each value of b for 10, but this would be time consuming and prone to error, and would be very frustrating if we wanted to re-calculate the result for a = 6 and b = 11! Using variables allows us to use and modify values multiple times within the code. Modify the code above to test for a = 6 and b = 11. Compare your answer with a friend, colleague, peer, family member or Zoom companion. Did you get the same result? Using variables is also important for repeatability. Lets say we want to calculate the sum of the squares from 1 to 5 i.e. \\(1^2 + 2^2 + 3^2 + 4^2 +5^2\\). We could write this numerically in R as follows: 1^2 + 2^2 + 3^2 + 4^2 + 5^2 This produces the current result: ## [1] 55 However, what if wanted to perform this calculation for all the numbers from 1 - 50 i.e. \\(1^2 + 2^2 + 3^2 + ... + 50^2\\)? What if we wanted to cube each value (i.e. \\(n^3\\)), rather than squaring? Either change would require a great deal of manual editing, with lots of potential for error. By comparison, using variables allows us to loop through a series of calculations. The code below creates a variable called result and loops through a sequence of numbers using seq() to perform the above calculation, where the variable i is updated each iteration. # Initialises a variable called result, with a value of 0 result &lt;- 0 # Loops through a sequence from 1 to 5 in increments of 1 (i.e. 1, 2, 3, 4, 5) for(i in seq(from = 1, to = 5, by = 1)){ # Squares each number (i) and adds to result result &lt;- result + i^2 } result ## [1] 55 Run the above code in the console. Try to modify the code to perform the calculation for 1 - 50; this should equal \\(42925\\) At this stage, dont worry about understanding the syntax of the code above. The important thing to remember is that using variables allows to us to perform more complex and more robust analyses. 3.3.1 Variable names When defining a variable name, you cant use spaces or characters that are not a-z, A-Z or 0-9. As a general rule, variables in R should be written in snake case (as opposed to upper case or lower case) where all words are in lower case and are separated by underscores (_). All of these are valid variable names in snake case: snake_case a_really_long_snake_case_name snake s Other popular naming conventions include camelCase, UPPER_CASE or hyphen-case (among many others). Pick one and use it consistently. 3.3.2 Variable types Each variable will have a particular type, which specifies what kind of a value it can hold. Whilst this is handled automatically for you by R, it is important that you understand what the different types are. Here are some common examples: # Character i.e. a string of letters, numbers and/or characters a &lt;- &quot;Bill&quot; # Numeric i.e. a number with decimals b &lt;- 3.567 # Integer c &lt;- 3 # Logical i.e. TRUE or FALSE d &lt;- TRUE Run the above code. If successful, your workspace should now include the variables a, b, c, d. Some data types are compatible e.g. # Numeric + integer b + c ## [1] 6.567 But others are not! # Numeric + character b + a ## Error in b + a: non-numeric argument to binary operator 3.4 Data structures In the previous examples, each variable has consisted of a single element. This could be a name (bill), a decimal number (3.567), an integer (3), and so on. However, R can store data in a range of different structures, many of which you will encounter as we progress through the course. 3.4.1 Vectors One of the simplest structures is the vector, which contains multiple elements of the same type. These are typically created using the command c(): # Creating a vector (v) of the numbers 1 - 5 v &lt;- c(1, 2, 3, 4, 5) v ## [1] 1 2 3 4 5 As a vector must have elements of the same type, R will try and coerce elements to the same type: # Creating a mixed vector (m) containing numeric (1,2), character (&quot;Bill&quot;, &quot;Ben&quot;) and logical elements (TRUE) m &lt;- c(1, 2, &quot;Bill&quot;, &quot;Ben&quot;, TRUE) m ## [1] &quot;1&quot; &quot;2&quot; &quot;Bill&quot; &quot;Ben&quot; &quot;TRUE&quot; In the above example, the numeric and logical elements have been coerced to characters, as signified by these elements being enclosed by quotation marks \" \". We can also create vectors programmatically, rather than manually defining each element. For example, we can generate sequences using seq() or repetitive sequences using rep(): # Creating a sequence from 1 to 5, in increments of 1 s &lt;- seq(from = 1, to = 5, by = 1) s ## [1] 1 2 3 4 5 # Creating a vector of length 5, consisting of the value 10 r &lt;- rep(10, times = 5) r ## [1] 10 10 10 10 10 3.4.2 Data frames Other common R data structures include matrices, lists and data frames. The data frame is the most commonly used structure for tabular data and will be familiar to those of you with experience in Microsoft Excel. Here is an example data frame, which is created by combining existing vectors of the same length: # Create numeric, character and logical vectors name &lt;- c(&quot;John&quot;, &quot;Eric&quot;, &quot;Michael&quot;, &quot;Graham&quot;, &quot;Terry&quot;, &quot;Terry&quot;) height &lt;- c(1.96, 1.85, 1.78, 1.88, 1.75, 1.73) nationality &lt;- c(&quot;British&quot;, &quot;British&quot;, &quot;British&quot;, &quot;British&quot;, &quot;American&quot;, &quot;British&quot;) bereft_of_life &lt;- c(FALSE, FALSE, FALSE, TRUE, FALSE, TRUE) # Combines into a data frame df &lt;- data.frame(name, height, nationality, bereft_of_life) df ## name height nationality bereft_of_life ## 1 John 1.96 British FALSE ## 2 Eric 1.85 British FALSE ## 3 Michael 1.78 British FALSE ## 4 Graham 1.88 British TRUE ## 5 Terry 1.75 American FALSE ## 6 Terry 1.73 British TRUE Run the above code in your R console Well be working with data frames throughout the practicals, so it will be useful to know that we can access data frame elements in a variety of different ways. We can access individual columns of a data frame using the $ operator, for example: # Extract the &quot;name&quot; column df$name ## [1] &quot;John&quot; &quot;Eric&quot; &quot;Michael&quot; &quot;Graham&quot; &quot;Terry&quot; &quot;Terry&quot; We can also extract using indexing, which requires us to provide the row and columns indexes in the following format: df[row.index, column.index] # Extract the element at row 3, column 4 df[3,4] ## [1] FALSE # Extract rows 1 to 4, all columns df[1:4,] ## name height nationality bereft_of_life ## 1 John 1.96 British FALSE ## 2 Eric 1.85 British FALSE ## 3 Michael 1.78 British FALSE ## 4 Graham 1.88 British TRUE # Extract rows 1 to 4, just the second column df[1:4, 2] ## [1] 1.96 1.85 1.78 1.88 # Extracts all rows, the second and third columns df[,2:3] ## height nationality ## 1 1.96 British ## 2 1.85 British ## 3 1.78 British ## 4 1.88 British ## 5 1.75 American ## 6 1.73 British We can also extract rows and columns based on the values within the data frame, for example using the subset() function. This can be used to select and exclude variables and observations as follows: # Extract data frame rows where height is more than or equal to (&gt;=) 1.8 m. subset(df, height &gt;= 1.8) ## name height nationality bereft_of_life ## 1 John 1.96 British FALSE ## 2 Eric 1.85 British FALSE ## 4 Graham 1.88 British TRUE # Extract data frames rows where nationality is not equal to (!=) American subset(df, nationality != &quot;American&quot;) ## name height nationality bereft_of_life ## 1 John 1.96 British FALSE ## 2 Eric 1.85 British FALSE ## 3 Michael 1.78 British FALSE ## 4 Graham 1.88 British TRUE ## 6 Terry 1.73 British TRUE # Extract data frames rows where bereft_of_life is equal to (==) FALSE subset(df, bereft_of_life == FALSE) ## name height nationality bereft_of_life ## 1 John 1.96 British FALSE ## 2 Eric 1.85 British FALSE ## 3 Michael 1.78 British FALSE ## 5 Terry 1.75 American FALSE Using the above code as an example, extract all the rows where name is equal to Terry. Assign the result to a new variable. You can calculate the number of rows using the function nrow(). Did you get the following answer? ## [1] 2 The sections above have given you a crash course in some of the fundamentals of R. Learning to code (or learning a new code syntax for those of your familiar with Python, MATLAB, Java, ) is similar to learning a new language. Dont worry if it seems complicated! You can always refer back to these instructions if you get stuck, or ask for guidance. To finish this Chapter, well provide a brief overview of some other key skills, including writing R scripts, loading data and packages, and plotting. This is not an exhaustive list of R functions, and well cover other functionality in Practicals 1 and 2 (e.g. loading GIS raster and vector data, creating maps and figures, performing statistical tests). However, the R functionality outlined here will cover all the steps required for the assessment and should equip you with the core skills required to progress further with R in the future. 3.5 Scripts So far weve been typing commands into the console. This works as expected; we can print results, store variables in the workspace and create plots in the plots window. However, it is often more convenient to store our code in a script, which is simply a file containing a set of commands and comments. For example, a single R script could contain commands to load data, perform statistical analysis, and output the results to a new file. This can be run in a single keystroke, which is much simpler than typing each command in one after another. To create a new R script: Navigate to File, New File and R Script. This should open a new window, with an untitled R script: To save the script: Navigate to File and Save As, and save it in the GEOG70581 folder with an appropriate name (e.g. learning_R) One of the easiest ways to run an entire script is to use Ctrl + Shift + Enter. Copy and paste the following code into your new script and run. The correct answer is 11.18034. # Length of sides a and b a &lt;- 5 b &lt;- 10 # Length of side c (Pythagoras) c &lt;- sqrt(a^2 + b^2) c However, you can also run aspects of a script by clicking on the individual line you want to run and using Ctrl + Enter. The same command applies if you highlight (select) multiple lines of code. 3.5.1 Comments When writing code, it is good practice to include comments which describe what the code does. As your code becomes more complex and as times passes, it is very easy to forget what your code does! Commenting your code is especially important if your code is being used by other people or even by yourself weeks/months/years in the future; save yourself time and effort by describing your code fully as you write it. Comments can be written in R using the # symbol. Any line of code which begins with # is ignored by R when the script is run and are used solely to improve the readability of the code. To add a comment, insert the # symbol and write some text. Below is some uncommented code. Copy and paste into your script and add some comments to describe what is taking place. a &lt;- seq(10, 100, 10) b &lt;- a/10 c &lt;- b*a plot(c, a) The above code is our first encounter with plot() which (as you may have guessed), is used to plot variables in base R.1 The new plot youve created should now appear in the plots window and should resemble the following figure. There are lots of more exciting ways to plot data in R, some of which are described below. As a general rule, well-presented code would typically comprise: 1/3 code; 1/3 empty space; 1/3 comments. This is known as the Rule of Thirds. 3.6 Loading packages Now that we have our script set up, one of the last things we need to understand is how to install and load packages in the R environment. To begin, remove all the previous code from your script learning_R.R and save. For the remainder of this chapter, we are going to use just one package as an example, but more will be required for Practicals 1 and 2, as detailed here. The package we are going to use is ggplot2, which is a widely used visualization package for R. If theres a figure, map or graphic you want to make, its likely that ggplot2 can do it for you. We can install the package using the helpfully named function install.packages() as follows: # Function to install packages. Name of package enclosed by quotation marks. install.packages(&quot;ggplot2&quot;) This function installs the package to your computer, but before we can use it, it needs to be activated within your current R session. This can be achieved by adding it to the library() as follows: # Function to add package to the library (no quotation marks) library(ggplot2) Copy and paste the two code snippets above into your script and run to install and load ggplot2. This is the standard approach to installing and loading packages in R. However, one of the weaknesses of this approach is that R will try and install and load each package every time the script is run. This is unnecessary; the package is already loaded! Try to re-install ggplot2 using the code above. The following pop-up should appear: Press No. The following message will appear in the console: Warning in install.packages : package ggplot2 is in use and will not be installed We can address this issue by using a user-defined function (called check.packages) to check whether a package is already installed. If it is installed, R will skip the installation. If it is not installed, R will install as normal. This function is similar to the functions weve been using before, such as sqrt() or seq(), which are available by default in base R; the difference is its been written from scratch! # Function to check and install packages check.packages &lt;- function(pkg){ new.pkg &lt;- pkg[!(pkg %in% installed.packages()[, &quot;Package&quot;])] if (length(new.pkg)) install.packages(new.pkg, dependencies = TRUE) sapply(pkg, require, character.only = TRUE) } # Checks and installs packages packages &lt;- c(&quot;ggplot2&quot;) check.packages(packages) Copy and paste the above code at the start of your R run script, removing the previous install.packages() and library() commands. Re-run the code. In future, you can add new packages by simply adding the package name to the packages vector. This works in exactly the same way as described previously, with the vector created using the c() command. For example, we could install packages as follows: packages &lt;- c(\"ggplot2\", \"dyplr\", \"raster\", \"sf\"). A full list of the available packages is here (&gt;18,000 and counting). Finally, packages should typically be installed and loaded at the start of any R script. If your code requires a package to run and it has not yet been installed, the code will fail. Installing and loading all the required packages at the start of the script avoids this problem. 3.7 Loading data In the final two sections of this chapter, we will load some data from a external file and plot using ggplot2. In the previous examples, weve been creating variables, vectors and data frames from scratch, but most data you will work with will be saved in another file format. This could be a comma-separated file (.csv), tab-delimited (.txt) or in an Excel format (.xls), or could be a spatial data type, such as a raster (.tif, .asc, .img) or vector (.shp). Being able to load and manipulate different data types is a key programming skill. Well use one of the most well-used formats as an example; the comma-separated file (.csv). This consists of rows and columns of data, where columns are delineated by commas. For example, here is an example of some comma-separated data: name,age,height,year_of_birth,instrument stewart,69,1.87,1952,drums andy,78,1.70,1942,guitar gordon,69,1.81,1951,vocals When read by R, it is interpreted as follows, splitting columns based on the occurrence of commas, and using the first row as column names: name age height year_of_birth instrument stewart 69 1.87 1952 drums andy 78 1.70 1942 guitar gordon 69 1.81 1951 vocals To load a .csv file into R, we can use the command read.csv(). The most basic way to load a file is to write the absolute file path. This is the location on your computer where the file is saved. For example, a file saved on your C drive, within your Documents folder, and within a folder called Manchester would be formatted as: C:\\Documents\\Manchester To find this, navigate in your file explorer (e.g. Windows Explorer, finder on macOS) to the data sub-directory within GEOG70581: The file containing the data is called flow_data.csv and contains the average daily river flow (m3 per second) from the National River Flow Archive and the UK Centre for Ecology &amp; Hydrology. The data are from a monitoring station on the River Nevis (#90003), which drains Ben Nevis, the highest mountain in the UK, and cover the period from the 1st October 1982 to the 30th September 2019. The file path to your file might read as follows (if your name was Bill): C:\\Users\\Bill\\GEOG-70581\\data\\flow_data.csv To load this file into R: Copy and paste this file path into your script, enclosing the file path within quotation marks. Importantly, R uses forward slashes within file paths /, whereas the file path in your file explorer probably uses backslashes \\, so these will need to be swapped. # Load data df &lt;- read.csv(&quot;C:/Users/Bill/Documents/GEOG-70581/data/flow_data.csv&quot;) If this has worked successfully, a new variable df will have been loaded into the workspace: As you may have noticed, this is not the most elegant way to load data, as it requires us to copy, paste and edit the full file path each time. This would quickly become tiring if we wanted to load multiple data sets. In Practical 1, well guide you through a solution using R projects and the here package but as ever, it is important to understand the basics before moving on to more sophisticated solutions. We can use a variety of commands to inspect this new data set, including: head(df) colnames(df) str(df) Run the above code. What do each of the commands do? head(), colnames(), str() What data types do we have in each column? See here for a reminder. What data structure are we working with? As outlined previously, we can access individual columns of a data frame using the $ operator and could start to do some simple analysis using base R functions, such as: # What is the average daily flow? mean(df$flow) ## [1] 6.544108 # What is the maximum daily flow? max(df$flow) ## [1] 131.9 # What is the minimum daily flow? min(df$flow) ## [1] 0.129 As outlined previously, we can also subset our data based on the values within the data frame, based on columns names ($) or using indexing. To simplify our subsequent analysis, were just going to work with data collected in 2019. The data frame rows which correspond to 2019 are from the 1st January [13242] to the 30th September [13514]. Extract these rows and all columns using indexing; see here for a reminder if you get stuck. You may also have noticed from the str() command that our column of dates (day/month/year) were stored as characters e.g. $ date: chr \"01/10/1982\". Working with dates and times is a complicated task (see this Tom Scott video for a light introduction to the problem), so to simplify plotting, well convert these characters e.g. \"01/10/1982\" into a date format. This can be achieved using the following code, which overwrites the date column in the data frame: df$date &lt;- and uses the function as.Date() to define a date format. In this case, our numbers are listed in day, month and then year, which is formatted in R as \"%d/%m/%Y\": # Converts dates (in character format) to date format df$date &lt;- as.Date(df$date, format = &quot;%d/%m/%Y&quot;) Once youve extracted the flow data from 2019, run the above code. 3.8 Plotting In the final task, were going to plot these data using ggplot2. One of the challenges of ggplot2 is its steep learning curve, but well walk through this example to show how we can progress from the raw data to high quality figures. These approaches will be useful for your assessment. To finish this chapter, copy and paste the following code elements into your R script in turn and run them. Make sure to read and understand what each step is doing. To begin, were going to create an empty ggplot canvas i.e. the blank canvas upon which we can add ggplot elements, such as axes, legends, data, scale bars etc. # Initialising an empty canvas ggplot() Next, we specify which data set we are going to plot. Note: ggplot2 works almost exclusively with data frames: # Which data frame do we want to use? ggplot(data = df) With the data frame defined, we now need to specify which columns of date we wish to plot. The code below uses the function mapping=aes()to do so, where the date variable is assigned to the x-axis x=date and the flow rate variable is assigned to the y-axis y=flow using their column names: # Which data frame columns do we want to plot? ggplot(data = df, mapping=aes(x=date, y=flow)) However, our data are still not visible because we need to select a geom type, which is a complicated way of saying the type of geometric object we want to plot. We could plot our data as points, lines or polygons; we could choose a histogram, bar plot, or box and whiskers plot; there are many to choose from! In this example, we are going to plot our data as points, which is done using the geom_point() command. As you can see from the code below, the structure differs slightly from normal code, in that ggplot elements are separated by the + operator. This allows the users to create complex figures while maintaining easy-to-read code. # What type of geom do we want? ggplot(data = df, mapping=aes(x=date, y=flow)) + geom_point() In the same way, we could also plot the same data as a line, using geom_line(). In this example, both geoms are using the same data frame as inputs x=date, y=flow: # Adding a line geom ggplot(data = df, mapping=aes(x=date, y=flow)) + geom_point() + geom_line() The above code covers the basics of ggplot, but we can start to improve the design of our plots. For example, we can choose one of the available themes: # Switching to the classic theme ggplot(data = df, mapping=aes(x=date, y=flow)) + geom_point() + geom_line() + theme_classic() We can re-order our geoms to show the data points above the line, while adding some colour using HEX codes: # Re-ordering the geoms, adding some colour ggplot(data = df, mapping=aes(x=date, y=flow)) + geom_line(colour = &quot;#56ACFF&quot;) + geom_point(colour = &quot;#767676&quot;) + theme_classic() We can also change the aspect ratio to produce a square plot: # Changing the aspect ratio ggplot(data = df, mapping=aes(x=date, y=flow)) + geom_line(colour = &quot;#56ACFF&quot;) + geom_point(colour = &quot;#767676&quot;) + theme_classic() + theme(aspect.ratio = 1) As a final step, we will probably want to export our figure so that it can be used elsewhere e.g. in a presentation or report or the assessment. To do so, we simply assign our ggplot object to a variable using the assignment operator: &lt;- as normal: # Assign our ggplot object to the variable &quot;g&quot; g &lt;- ggplot(data = df, mapping=aes(x=date, y=flow)) + geom_line(colour = &quot;#56ACFF&quot;) + geom_point(colour = &quot;#767676&quot;) + theme_classic() + theme(aspect.ratio = 1) Finally, we can save our ggplot object using the ggsave() function, as shown below. This takes in the name of the plot (g), as well as the intended name, extension and file path e.g. \"C:/Users/Bill/Documents/GEOG-70581/images/flow_data_2019.png\". In this example, we are saving our output within the images sub-directory of GEOG-70581. We have also defined the name of the file flow_data_2019 and specified its file type: .png (portable network graphics file). We can also modify other settings, such as the dpi which determines the plot resolution. A list of ggsave options can be found here. # Saves to a png ggsave(plot = g, &quot;C:/Users/Bill/Documents/GEOG-70581/images/flow_data_2019.png&quot;, dpi = 150) ## Saving 7 x 5 in image Run the above code to assign your plot to the variable g and export it to your images folder, making sure to update the file path! We have now exported our plot and should be able to see it in the images sub-directory of GEOG-70581. Importantly, and for future plots, you dont need to run the commands in the sequence shown above e.g. first creating a canvas ggplot(), then defining a data frame ggplot(data = df), and so on. This sequence was used to show you how we can add elements to the ggplot object, building from the blank canvas to exporting the final figure. Congratulations! You have now completed Chapter 3: the not-so-brief introduction to R. While this may have been challenging, we have covered most of the core skills which you will need. You should now have an appreciation of the the different data types and structures that are available in R, experience running code in the console and within scripts, and the ability to install packages, load data and create plots. Well use many of these techniques in Practicals 1 and 2. Base R is used to refer to the functions that are part of the core packages deployed with R, such as plot(), sqrt() or seq(). As we install and utilise user-created packages, we are moving away from base R. "],["FirstPractical.html", "Chapter 4 Eskdale I - Introduction 4.1 Overview", " Chapter 4 Eskdale I - Introduction It should be evident from the lectures that digital elevation models (DEMs) have a great deal of potential for modelling surface water hydrology and related phenomena in drainage basins. Much of this work is based on the assumptions that (1) we can trace the path that water will take from any point in an elevation grid to a basin outlet, and (2) the discharge of water from a particular location is directly related to its catchment area. This is a fairly reasonable assumption in most drainage basins. 4.1 Overview In this lab exercise, we will use a DEM of the Upper Eskdale catchment to model flow-related phenomena, and will have gained experience in: DEM pre-processing; Calculating flow parameters (e.g. pointers and contributing areas); Comparing flow algorithms. Upper Eskdale catchment 4.1.1 Intended learning outcomes In Chapter 5, well download the data and install the required programs and packages, and will combine these in Chapter 6 to: gain experience with WhiteboxTools, a specialist GIS specifically designed for digital terrain analysis (DTA); become familiar with some of the most commonly used flow algorithms used to simulate overland flow from digital elevation models (DEMs); consider the utility of DTA for routing applications; 4.1.2 Assessment This practical is formative and as such will not count towards your final mark for GEOGz70581, but you are encouraged to complete the practical to the best of your ability, and to have one or more attempts at the formative quiz. 4.1.3 Quiz There is an on-line Blackboard quiz associated with this practical that you are encouraged to complete. The quiz can be found in the Week Seven practical folder on the Blackboard site for this course. The quiz consists of six questions. You can have multiple attempts at the quiz. "],["Eskdale_set_up.html", "Chapter 5 Eskdale II - Set-up 5.1 Install programs 5.2 Download data 5.3 Open RStudio 5.4 Initialise an R project 5.5 Creating an R script 5.6 Install WhiteboxTools 5.7 Loading packages", " Chapter 5 Eskdale II - Set-up 5.1 Install programs If you havent installed R and RStudio, please refer to the instructions here before continuing. 5.2 Download data The data for this practical can be downloaded here. Download the folder, save it to an appropriate location and extract the contents (unzip). The directory structure is as follows: GEOG70581 Data Practical_1 Practical_2 Images Practical_1 Practical_2 Output Practical_1 Practical_2 All the required data files for Practicals 1 and 2 are stored in the associated sub-directory within Data. As we move through the practicals, well be creating a number of additional GIS files and we encourage you to save these within the corresponding sub-directory within Output. Finally, maps and figures will be required for the assessment. These can be exported directly from R and stored in Images. 5.3 Open RStudio To begin, open RStudio. 5.4 Initialise an R project In the previous chapter, we typed commands into the console and used R scripts to store commands and comments. For both Practicals 1 and 2, we are going to expand on these by also utilising R projects. Projects make life simpler by allowing us to access file locations (e.g. loading and writing data) using relative file paths, rather than using the clunky and prone-to-breaking absolute file paths. Relative file paths work by setting the working directory, which is simply the the default location where R will look for files you want to load and where it will put any files you save. We can do this manually by using the setwd() function, but a simpler approach is to use an R project, which sets the working directory for your automatically. Rather than the complicated absolute file paths: &quot;C:/Users/Bill/Documents/GEOG-70581/data/flow_data.csv&quot; which indicates that the file is located in data, which is within GEOG-70581, which is within Documents, which is within Bill, which is within Users, which is on the C drive, we can set the working directory to GEOG-70581 (for example) and then access the file using the here package: here(&quot;data&quot;, &quot;flow_data.csv&quot;) This approach not only makes it easier to access files, but also improves reproducibility. Using projects ensures that our work is self-contained (the project directory contains all the data, scripts and outputs) and portable. Transferring the project directory to another user, to a different sub-folder on your computer, or a different drive, would not cause any code to fail. By comparison, scripts featuring absolute file paths would likely fail in any of the above scenarios. To initialise a new R project: Go to File, New Project, and select Existing Directory. Using the Browse icon, set the project working directory to the folder GEOG70581, which you downloaded and unzipped here. Select Create new project If this has been successful, your console should have been updated to include the path to your project working directory as follows: 5.5 Creating an R script Now that we have created our project for GEOG70581, we are going to use scripts to store the code for each practical. Well create a script for Practical 1 and a separate script for Practical 2. For Practical 1: Navigate to File, New File and R Script. To save the script: Navigate to File and Save As, and save it in the GEOG70581 folder with an appropriate name (e.g. Practical-1-Eskdale) This should now resemble the following: 5.6 Install WhiteboxTools For Practical 1, we are going to use the following packages: ggplot2 for data visualisation; here to construct paths to your project files; raster for reading, analysing and writing of raster and vector data; sf for simple storage of vector data; `ggspatial for simple plotting of raster data in ggplot2; whitebox for geospatial analysis (a front-end for WhiteboxTools); Most of these packages can be installed as normal using the install.packages() and library() functions. The exception to this is whitebox, because (for complicated reasons) it is not currently available on the Comprehensive R Archive Network (CRAN). However, it is available on R-Forge. While CRAN is the official package repository for R and generally features release versions of packages, R-Forge provides candidate, beta or work-in-progress packages or packages which dont meet the criteria for inclusion on CRAN. We can install R-forge packages as normal using the install.packages() function, but have to specify the repository (web location) where it is stored, in this case: http://R-Forge.R-project.org. Paste the following code into your R script and run to install whitebox # Installs whitebox from R-Forge install.packages(&quot;whitebox&quot;, repos=&quot;http://R-Forge.R-project.org&quot;) If successful, the console window should update as the installation progresses and should finish by printing the directory where the package is saved e.g. The downloaded source packages are in C:\\file-path-here\\downloaded_packages. One additional step, which is different from normal R package installation, is to use the function whitebox::wbt_init(), which initialises WhiteboxTools: # Initialise WBT whitebox::wbt_init() Performing one-time download of WhiteboxTools binary from https://jblindsay.github.io/ghrg/WhiteboxTools/WhiteboxTools_win_amd64.zip (This could take a few minutes, please be patient...) WhiteboxTools binary is located at: C:/Users/44797/OneDrive/Documents/R/win-library/4.0/whitebox/WBT/whitebox_tools.exe You can now start using whitebox &gt; library(whitebox) &gt; wbt_version() This code checks if a suitable WhiteboxTools executable is present (.exe) and installs if missing. The WhiteboxTools executable contains all the code used for geospatial analysis, which we then access using R via the whitebox R package. This is a slightly different configuration from normal R packages but enables WhiteboxTools to be used cross-platform i.e. WhiteboxTools functionality stored in the executable can be assessed through R, Python, ArcGIS or QGIS etc, depending on the user needs. Run the above code to initialise WhiteboxTools, which should perform a one-time download of the WhiteboxTools binary (executable) When complete, WhiteboxTools has now been successfully installed and initialised and is almost ready to be used. However, to avoid re-installing and re-initialisng WBT every time we run our script, we can either delete the code or comment-out # each line. Remember that R ignores any line of comment that begins with #: # Code to install whitebox from R-forge and initialise # install.packages(&quot;whitebox&quot;, repos=&quot;http://R-Forge.R-project.org&quot;) # whitebox::wbt_init() Either delete or comment-out the previous commands (install.packages(), wbt_init). Ctrl + Shift + C is a useful shortcut for adding or removing comments from multiple lines of highlighted code. 5.7 Loading packages To finish the set-up for Practical 1, we are going to install the remaining required R packages (described above) and load them into the R library. Weve already practiced installing and loading the ggplot2 package in Chapter 2 so you are ready for the following: Referring back to the instructions here, install and load ggplot2, here, raster, sf, ggspatial and whitebox. Hint 1 - weve already installed whitebox, so this can be excluded if youre using install.packages() and the library() commands. Hint 2 - the user-defined function check.packages might be useful here. ## ggplot2 ggspatial here raster sf whitebox ## TRUE TRUE TRUE TRUE TRUE TRUE If the package has been installed and loaded correctly, the console should print the following: ggplot2 here raster sf whitebox ggspatial TRUE TRUE TRUE TRUE TRUE TRUE where the logical value TRUE equates to a successful installation (and vice versa for FALSE). "],["Eskdale_flow_algorithms.html", "Chapter 6 Eskdale III - Flow routing 6.1 DEM pre-processing: flow enforcement 6.2 Calculating Flow Parameters: Pointers 6.3 Comparing flow algorithms", " Chapter 6 Eskdale III - Flow routing Overland and near-surface water flow can be modelled using DEMs if we assume that surface topography is the sole factor which influences the distribution of water. One very simple model routes all water from a particular grid cell in a DEM to a single neighbouring cell (i.e. water is not partitioned between multiple neighbours). This D8 (8 direction) method sets the flow direction toward the lowest of the eight neighbouring cells, in relation to the centre cell. Figure 1: Schematic of the D8 method. The elevation value of the centre cell is 8 m (dark blue). Under atmospheric pressure, water flows to areas of lower elevation (&lt; 8 m; light blue) and does not flow to areas of higher elevation (&gt;8 m; grey). In this case, the D8 method would route all the water from the centre cell into the bottom left cell, as it has the lowest value (4 m). Using this method, water flow is allowed in one of eight possible directions (       ), assuming that water will travel along the steepest downslope path. In turn, the method is sometimes referred to as the steepest descent method. Based on the \\(3 * 3\\) cell neighbourhood shown in Figure 1, flow would be directed from the centre cell (8 m elevation) to the southwest cell (4 m elevation). 6.1 DEM pre-processing: flow enforcement One common issue encountered when performing hydrological analyses is the presence of sinks, which interrupt the drainage network. When sinks are encountered, flow direction is undefined when a grid cell, or group of grid cells, is lower than all neighbouring cells (see Figure 2) When sinks are encountered, and when there are no downslope neighbours, all water that enters a cell is unable to escape. These features are referred to as pits if they are a single cell in size, and depressions if they consist of groups of cells. Figure 2: Schematic of a sink in a DEM. In this \\(5 * 5\\) matrix, water is routed into the top right cell (9 m) and then is routed to the lowest elevation cell at each step (9 m  8 m  7 m  6 m  2 m) using the D8 method (blue cells). However, the drainage network is interrupted by a sink at the 2 m cell (orange), as all neighbouring cells are of higher elevation. Sinks can often be artefacts of the data and should be removed during DEM pre-processing. Pre-processing involves altering the elevations of the DEM in a way that enforces continuous flow-paths. However, it is important to realise that sometimes these digital depressions reflect actual features in the landscape, and should be preserved during flow modelling. This is a particular issue for hydrological analysis of karst environments, where water can be routed into dolines and fractures. However, for our work, we will assume that all depressions in DEMs are artefacts and are justified in being removed. Several methods have been developed for removing depressions from DEMs. These methods vary greatly in terms of their sophistication and impact on the DEM. The two most common depression removal methods Figure 3 are: depression filling, which raises cells within a depression to the elevation of the outlet cell; depression breaching, which digs a trench from a depressions bottom to some point downslope. Figure 3: Schematic of depression filling and breaching in a DEM. Using the same values from Figure 2, original values are modified to allow water to escape the sink (orange). Depression filling has raised the value of the sink (2 m  4 m), while depression breaching has lowered the value of a neighbouring cell (3 m  1 m). In this simplified example, the outputs of these two distinct approaches are identical but care should be taken when working with real world data as they will often produce different results. Not all interruptions to flow routing are caused by depression cells. Often, DEMs contain extensive flat regions (areas of equal elevation). Flat areas interrupt flow routing in the same way as depressions. Cells within a flat region do not have downslope neighbours, and therefore, flow routing is impossible on flat sites without pre-processing. Correction of flow direction on flat sites typically involves finding an outlet cell, forcing flow from cells adjacent to the outlet to the outlet, and continuing backwards in an iterative manner (e.g., Jenson and Domingue (1988)). 6.1.1 Application The DEM we are working with is centred on the Upper Eskdale catchment; an upland valley which drains the highest mountain in England (Scafell Pike; 978 m), as shown below: Figure 4: Upper Eskdale panorama, viewed from Harter Fell [Location: 54.386907, -3.205004, Elevation: 649 m]. The catchment ranges in elevation from 978 m (Scafell Pike) to ~160 m at the catchment outlet (white circle), and is ringed by numerous summits with elevations in excess of 800 m (white triangles). The catchment has an area of ~15.7 km2 and all water which falls with the catchment ultimately drains to the Irish Sea via the River Esk. The DEM we are working with was downloaded from EDINA Digimap, has a cell size of 10 m and uses the British National Grid (BNG), a projected coordinate Reference System [EPSG:27700]. Unfortunately, we dont have time in this course to delve into the exciting world of map projections, although these are covered excellently by Dr. Jonny Huck in the Semester 2 course Understanding GIS. However, it is important to know that different map projections have different uses and work more/less effectively in different spatial areas. As we are working within the UK, it makes sense to use a map projection which is tailored to the UK (e.g. BNG) as this minimises different types of map distortion (length, shape, area). When loaded into R using the raster package and plotted using ggplot2 and ggspatial, our DEM can be visualised as follows, where the outlet point (white circle) and summits (black triangles) match those shown in Figure 4. To accentuate areas of relief, the DEM has been combined with a semi-transparent hillshade layer, which is shown below: To evaluate the effects of depression breaching and filling, were going to DEM of the Upper Eskdale catchment # Sets file path for DEM dem &lt;- here(&quot;data&quot;, &quot;practical_1&quot;, &quot;dem_10m.tif&quot;) # Breach and fills depressions wbt_fill_depressions(dem, here(&quot;output&quot;, &quot;practical_1&quot;, &quot;dem_10m_fill.tif&quot;)) wbt_breach_depressions(dem, here(&quot;output&quot;, &quot;practical_1&quot;, &quot;dem_10m_breach.tif&quot;)) 6.2 Calculating Flow Parameters: Pointers 6.3 Comparing flow algorithms # Analysis  # Sets file path for DEM dem &lt;- here(&quot;data&quot;, &quot;practical_1&quot;, &quot;dem_10m.tif&quot;) # Breach and fills depressions wbt_fill_depressions(dem, here(&quot;output&quot;, &quot;practical_1&quot;, &quot;dem_10m_fill.tif&quot;)) wbt_breach_depressions(dem, here(&quot;output&quot;, &quot;practical_1&quot;, &quot;dem_10m_breach.tif&quot;)) # Calculates D8 pointer wbt_d8_pointer(here(&quot;output&quot;, &quot;practical_1&quot;, &quot;dem_10m_breach.tif&quot;), here(&quot;output&quot;, &quot;practical_1&quot;, &quot;dem_10m_D8_pointer.tif&quot;)) # Calculates accumulation file wbt_d8_flow_accumulation(here(&quot;output&quot;, &quot;practical_1&quot;, &quot;dem_10m_breach.tif&quot;), here(&quot;output&quot;, &quot;practical_1&quot;, &quot;dem_10m_flow_accumulation.tif&quot;)) # Extracts streams, accumulation threshold of 500 wbt_extract_streams(here(&quot;output&quot;, &quot;practical_1&quot;, &quot;dem_10m_flow_accumulation.tif&quot;), here(&quot;output&quot;, &quot;practical_1&quot;, &quot;dem_10m_streams_act500.tif&quot;), 500) # Snaps pour points to stream network, snap distance in map units (50 = 50 m) wbt_jenson_snap_pour_points(here(&quot;data&quot;, &quot;practical_1&quot;, &quot;pour_point.shp&quot;), here(&quot;output&quot;, &quot;practical_1&quot;, &quot;dem_10m_streams_act500.tif&quot;), here(&quot;output&quot;, &quot;practical_1&quot;, &quot;dem_10m_pour_point_snapped.shp&quot;), snap_dist = 50) # Watershed from pour points wbt_watershed(here(&quot;output&quot;, &quot;practical_1&quot;, &quot;dem_10m_D8_pointer.tif&quot;), here(&quot;output&quot;, &quot;practical_1&quot;, &quot;dem_10m_pour_point_snapped.shp&quot;), here(&quot;output&quot;, &quot;practical_1&quot;, &quot;dem_10m_watersheds.tif&quot;)) # Converts watershed to vector format (polygon) wbt_raster_to_vector_polygons(here(&quot;output&quot;, &quot;practical_1&quot;, &quot;dem_10m_watersheds.tif&quot;), here(&quot;output&quot;, &quot;practical_1&quot;, &quot;dem_10m_watersheds.shp&quot;)) # Converts streams to vector format (lines) wbt_raster_to_vector_lines(here(&quot;output&quot;, &quot;practical_1&quot;, &quot;dem_10m_streams_act500.tif&quot;), here(&quot;output&quot;, &quot;practical_1&quot;, &quot;dem_10m_streams_act500.shp&quot;)) References "],["SecondPractical.html", "Chapter 7 Practical 2 - Mersey 7.1 Part 1: Overview", " Chapter 7 Practical 2 - Mersey Within a Geographical Information System (GIS) framework, readily available spatial datasets, such as land use and geology, have been used to explore the controls on river water quality. Understanding the relationships between catchment characteristics (or metrics) and river water quality provides a base for determining how future changes in both land use and climate will impact river water quality. Therefore, it is important to determine the processes that regulate river water quality in landscapes under increasing pressure from human population, whether from urbanisation or more intensive food production. The Mersey Basin is one of the UKs most environmentally varied regions, with rich rural landscapes and urban-industrial centres. Industrial prosperity in the region over the last few hundred years resulted in severe pollution of the many rivers in the basin. Although there has been significant improvements in water quality in recent years the rivers in the Mersey Basin are still subjected to a number of sewage and industrial inputs, and agricultural runoff. 7.1 Part 1: Overview In this practical you will explore the controls on river water quality in the Mersey Basin and develop empirical models of river water quality across the region. 7.1.1 Topics covered in this practical Terrain analysis, including catchment delineation and derivation of catchment characteristics; Writing and execution of scripts; Multiple Linear Regression to create models of catchment hydrochemistry; Using models to create spatial predictions of catchment hydrochemistry using WhiteboxTools. 7.1.2 Intended Learning Outcomes Gain practical experience of modelling environmental phenomena using a Geographical Information Systems (GIS) framework; Gain practical experience of hydrological modelling using GIS; Gain practical experience of manipulating and analysing raster datasets; Gain practical experience of using Map Algebra functions and writing scripts; Gain practical experience of using multivariate analysis; Understand some of the key controls on river water quality; Be able to critically evaluate model outputs. 7.1.3 Assessment This practical is assessed by completion of the tasks outlined in this document, full details of which are provided here. You will need to write up the practical in the format of a report. This practical is worth 50% of your overall mark for GEOG70581. As well as the standard SEED PGT criteria, you will also be assessed on your ability to: Effectively follow instructions to complete the practical tasks (technical prowess), i.e. producing the regression equations and output images correctly; Analyse and interpret the outputs in the context of your knowledge of river hydrochemistry (and with reference to appropriate literature); Relate the monitoring and modelling approaches here to theory covered earlier in the course (and with reference to appropriate literature); Explain ideas clearly and concisely; Present figures and data clearly and effectively; Be original and insightful in terms of independent research and additional analysis of the data where appropriate. Use references to relevant academic literature to support your arguments; The deadline for this practical is 2pm on Thursday 4th February 2021. The word count for this practical is 2,000. For Practical 2, we are also going to use data.table, forcats and dplyr for data management, and MASS and viridis for analysis/visualisation respectively. forcats &lt;- fct_collapse viridis data.table &lt;- table [units] dplyr MASS [glmnet] "],["Assessment.html", "Chapter 8 Assessment", " Chapter 8 Assessment Title: Modelling River Hydrochemistry Word Limit: 2000. The guidelines provided in the CO2 flux practical, which outline what is and what is not included in the word count, as well penalties for exceeding the word count, also apply here. Format: Report Structure: Your report should be a coherent document, as opposed to a list of Q&amp;As as with the CO2 flux practical. Within this, how you structure the report is your decision. However, there are certain items that must be included in the main body of the report. These are the regression equations (and associated information i.e. significance values, R2 etc) for all ten water quality indicators, and your three spatial predictions of river water quality. You can choose which three water quality indicators you focus on for the spatial predictions, but you should justify your choice in the report. As well as these important items, the following points must be covered in the report: What are the relationships between water quality and catchment characteristics? Are there any consistent predictors of water quality? How good are the regression models? What sort of errors may occur during the derivation of catchment characteristics? How could these errors be minimised? How could you validate the models? Are there any patterns in modelled river water quality? Are your predictive maps of water quality useful? Are there any errors / limitations when constructing maps of this type? How could you improve the spatial predictions? Your report should not just be a reworked version of the practical instructions. In fact, there is no need to include a methodology section at all, although you may wish to reflect on the methods used when considering the points above. You may find it useful to refer to the my learning essential resources on report writing ([https://www.library.manchester.ac.uk/using-the-library/students/training-and-skills-support/my-learning-essentials/online-resources/) In addition to the above, you must produce maps for each of the following files created during the practical exercise. These are listed using the file names used above, but check these carefully if you used a different naming format. These need to be included in an Appendix at the back of the report (ideally two images per page): D8 specific contributing areas (SCA)  (mersey_DEM_fill_D8_SCA); Watersheds in the Mersey Basin, derived from the 70 modified Environment Agency seed points  (mersey_watersheds); Boolean (logical) raster of urban land cover  (mersey_LC_Urban); Boolean (logical) raster of permeable HOST soil cover  (mersey_HOST_Perm); Boolean (logical) raster of coal bedrock  (mersey_bedrock_Coal); Slope map  (mersey_DEM_fill_slope); Streams raster, created using the specific contributing area (SCA) and a channelization threshold of 10 (log-transformed)  (mersey_Streams_SCA10); Masked sub-basins  (mersey_subsbasin_mask). Presentation of Images: All maps should have a scale bar, north arrow and legend, all of which can be added in Whitebox under the Cartographic dropdown menu. Maps can be exported from Whitebox to image format (e.g. .png) using Export Map as Image. Referencing: The report should be fully referenced, using the Harvard style. You should not just adapt the text from the Rothwell paper, substituting key values for the data here. This will result in a high similarity index and you may face a penalty due to poor academic practice. You must write up the report in your own words, making sure you paraphrase the ideas of others, and reference fully throughout. Submission deadline: XX/XX/XXXX, XX:XX "],["404.html", "Page not found", " Page not found The page you requested cannot be found (perhaps it was moved or renamed). You may want to try searching to find the page's new location, or use the table of contents to find the page you are looking for. "]]
