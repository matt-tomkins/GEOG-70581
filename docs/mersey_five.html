<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>Chapter 4 Mersey V - Statistical analysis | Practical_1.knit</title>
  <meta name="description" content="<center>
Hydrological analysis in R
</center>" />
  <meta name="generator" content="bookdown 0.23 and GitBook 2.6.7" />

  <meta property="og:title" content="Chapter 4 Mersey V - Statistical analysis | Practical_1.knit" />
  <meta property="og:type" content="book" />
  
  
  
  

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Chapter 4 Mersey V - Statistical analysis | Practical_1.knit" />
  
  
  




  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="Intro_to_R.html"/>

<script src="libs/jquery-3.6.0/jquery-3.6.0.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />









<script src="libs/accessible-code-block-0.0.1/empty-anchor.js"></script>
<link href="libs/anchor-sections-1.0.1/anchor-sections.css" rel="stylesheet" />
<script src="libs/anchor-sections-1.0.1/anchor-sections.js"></script>
<script src="libs/htmlwidgets-1.5.3/htmlwidgets.js"></script>
<link href="libs/leaflet-1.3.1/leaflet.css" rel="stylesheet" />
<script src="libs/leaflet-1.3.1/leaflet.js"></script>
<link href="libs/leafletfix-1.0.0/leafletfix.css" rel="stylesheet" />
<script src="libs/proj4-2.6.2/proj4.min.js"></script>
<script src="libs/Proj4Leaflet-1.0.1/proj4leaflet.js"></script>
<link href="libs/rstudio_leaflet-1.3.1/rstudio_leaflet.css" rel="stylesheet" />
<script src="libs/leaflet-binding-2.0.4.1/leaflet.js"></script>
<script src="libs/leaflet-providers-1.9.0/leaflet-providers_1.9.0.js"></script>
<script src="libs/leaflet-providers-plugin-2.0.4.1/leaflet-providers-plugin.js"></script>


<style type="text/css">
code.sourceCode > span { display: inline-block; line-height: 1.25; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode { white-space: pre; position: relative; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
code.sourceCode { white-space: pre-wrap; }
code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>


</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li class="chapter" data-level="1" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i><b>1</b> Introduction</a><ul>
<li class="chapter" data-level="1.1" data-path="index.html"><a href="index.html#practical-outline"><i class="fa fa-check"></i><b>1.1</b> Practical outline</a></li>
<li class="chapter" data-level="1.2" data-path="index.html"><a href="index.html#objectives"><i class="fa fa-check"></i><b>1.2</b> Objectives</a></li>
<li class="chapter" data-level="1.3" data-path="index.html"><a href="index.html#schedule"><i class="fa fa-check"></i><b>1.3</b> Schedule</a></li>
</ul></li>
<li class="chapter" data-level="2" data-path="Installation.html"><a href="Installation.html"><i class="fa fa-check"></i><b>2</b> Installation</a><ul>
<li class="chapter" data-level="2.1" data-path="Installation.html"><a href="Installation.html#r"><i class="fa fa-check"></i><b>2.1</b> R</a></li>
<li class="chapter" data-level="2.2" data-path="Installation.html"><a href="Installation.html#r-studio"><i class="fa fa-check"></i><b>2.2</b> R Studio</a></li>
<li class="chapter" data-level="2.3" data-path="Installation.html"><a href="Installation.html#materials"><i class="fa fa-check"></i><b>2.3</b> Course materials</a></li>
</ul></li>
<li class="chapter" data-level="3" data-path="Intro_to_R.html"><a href="Intro_to_R.html"><i class="fa fa-check"></i><b>3</b> A (brief) introduction to R</a><ul>
<li class="chapter" data-level="3.1" data-path="Intro_to_R.html"><a href="Intro_to_R.html#overview"><i class="fa fa-check"></i><b>3.1</b> Overview</a><ul>
<li class="chapter" data-level="3.1.1" data-path="Intro_to_R.html"><a href="Intro_to_R.html#what-is-r"><i class="fa fa-check"></i><b>3.1.1</b> What is R?</a></li>
<li class="chapter" data-level="3.1.2" data-path="Intro_to_R.html"><a href="Intro_to_R.html#why_code"><i class="fa fa-check"></i><b>3.1.2</b> Why code?</a></li>
<li class="chapter" data-level="3.1.3" data-path="Intro_to_R.html"><a href="Intro_to_R.html#a-quick-note-on-the-practicals"><i class="fa fa-check"></i><b>3.1.3</b> A quick note on the practicals</a></li>
<li class="chapter" data-level="3.1.4" data-path="Intro_to_R.html"><a href="Intro_to_R.html#dealing-with-errors"><i class="fa fa-check"></i><b>3.1.4</b> Dealing with errors</a></li>
</ul></li>
<li class="chapter" data-level="3.2" data-path="Intro_to_R.html"><a href="Intro_to_R.html#loading-r"><i class="fa fa-check"></i><b>3.2</b> Loading R</a></li>
<li class="chapter" data-level="3.3" data-path="Intro_to_R.html"><a href="Intro_to_R.html#variables-looping"><i class="fa fa-check"></i><b>3.3</b> Variables</a><ul>
<li class="chapter" data-level="3.3.1" data-path="Intro_to_R.html"><a href="Intro_to_R.html#variable-names"><i class="fa fa-check"></i><b>3.3.1</b> Variable names</a></li>
<li class="chapter" data-level="3.3.2" data-path="Intro_to_R.html"><a href="Intro_to_R.html#variables_types"><i class="fa fa-check"></i><b>3.3.2</b> Variable types</a></li>
</ul></li>
<li class="chapter" data-level="3.4" data-path="Intro_to_R.html"><a href="Intro_to_R.html#data-structures"><i class="fa fa-check"></i><b>3.4</b> Data structures</a><ul>
<li class="chapter" data-level="3.4.1" data-path="Intro_to_R.html"><a href="Intro_to_R.html#vectors"><i class="fa fa-check"></i><b>3.4.1</b> Vectors</a></li>
<li class="chapter" data-level="3.4.2" data-path="Intro_to_R.html"><a href="Intro_to_R.html#data_frames"><i class="fa fa-check"></i><b>3.4.2</b> Data frames</a></li>
</ul></li>
<li class="chapter" data-level="3.5" data-path="Intro_to_R.html"><a href="Intro_to_R.html#scripts"><i class="fa fa-check"></i><b>3.5</b> Scripts</a><ul>
<li class="chapter" data-level="3.5.1" data-path="Intro_to_R.html"><a href="Intro_to_R.html#comments"><i class="fa fa-check"></i><b>3.5.1</b> Comments</a></li>
</ul></li>
<li class="chapter" data-level="3.6" data-path="Intro_to_R.html"><a href="Intro_to_R.html#packages"><i class="fa fa-check"></i><b>3.6</b> Loading packages</a></li>
<li class="chapter" data-level="3.7" data-path="Intro_to_R.html"><a href="Intro_to_R.html#data_loading"><i class="fa fa-check"></i><b>3.7</b> Loading data</a></li>
<li class="chapter" data-level="3.8" data-path="Intro_to_R.html"><a href="Intro_to_R.html#data_plotting"><i class="fa fa-check"></i><b>3.8</b> Plotting</a></li>
<li class="chapter" data-level="3.9" data-path="Intro_to_R.html"><a href="Intro_to_R.html#formative_task"><i class="fa fa-check"></i><b>3.9</b> Formative task</a><ul>
<li class="chapter" data-level="3.9.1" data-path="Intro_to_R.html"><a href="Intro_to_R.html#formative-solution"><i class="fa fa-check"></i><b>3.9.1</b> Formative solution</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="4" data-path="mersey_five.html"><a href="mersey_five.html"><i class="fa fa-check"></i><b>4</b> Mersey V - Statistical analysis</a><ul>
<li class="chapter" data-level="4.1" data-path="mersey_five.html"><a href="mersey_five.html#task-7-model-building"><i class="fa fa-check"></i><b>4.1</b> Task 7: Model building</a><ul>
<li class="chapter" data-level="4.1.1" data-path="mersey_five.html"><a href="mersey_five.html#an-introduction-to-linear-models-in-r"><i class="fa fa-check"></i><b>4.1.1</b> An introduction to linear models in R</a></li>
<li class="chapter" data-level="4.1.2" data-path="mersey_five.html"><a href="mersey_five.html#training-vs.-testing"><i class="fa fa-check"></i><b>4.1.2</b> Training vs. Testing</a></li>
<li class="chapter" data-level="4.1.3" data-path="mersey_five.html"><a href="mersey_five.html#variable-selection-strategies"><i class="fa fa-check"></i><b>4.1.3</b> Variable selection strategies</a></li>
</ul></li>
<li class="chapter" data-level="4.2" data-path="mersey_five.html"><a href="mersey_five.html#task-8-model-evaluation"><i class="fa fa-check"></i><b>4.2</b> Task 8: Model evaluation</a></li>
</ul></li>
</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./"><center>
Hydrological analysis in R
</center></a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="mersey_five" class="section level1">
<h1><span class="header-section-number">Chapter 4</span> Mersey V - Statistical analysis</h1>
<p>In this final chapter, we will compare the information about catchment characteristics with the water quality data collected at each of the 70 monitoring stations. To begin, load the csv file created at the end of Task 6 (<code>mersey_watersheds_ea.csv</code>), saving to a new variable called <code>watersheds_df</code>:</p>
<div class="sourceCode" id="cb65"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb65-1"><a href="mersey_five.html#cb65-1"></a><span class="co"># Reads completed file from csv</span></span>
<span id="cb65-2"><a href="mersey_five.html#cb65-2"></a>watersheds_df &lt;-<span class="st"> </span><span class="kw">read.csv</span>(<span class="kw">here</span>(<span class="st">&quot;output&quot;</span>, <span class="st">&quot;practical_2&quot;</span>, <span class="st">&quot;mersey_watersheds_ea.csv&quot;</span>))</span></code></pre></div>
<p>If you have any other variables in your R environment, these can be removed using <code>rm()</code>.</p>
<div id="task-7-model-building" class="section level2">
<h2><span class="header-section-number">4.1</span> Task 7: Model building</h2>
<p>This data frame should contain the following 10 water quality indicators for each watershed:</p>
<ul>
<li>pH: acidity/alkalinity;</li>
<li>SSC: suspended solids concentration;</li>
<li>Ca: calcium;</li>
<li>Mg: magnesium;</li>
<li>NH<sub>4</sub>: ammonium;</li>
<li>NO<sub>3</sub>: nitrate;</li>
<li>NO<sub>2</sub>: nitrite;</li>
<li>TON: total oxidised nitrogen;</li>
<li>PO<sub>4</sub>: phosphate;</li>
<li>Zn: zinc.</li>
</ul>
<p>It should also contain the continuous derivatives (e.g. average elevation) and categorical derivatives (e.g. land cover percentage) for each watershed.</p>
<p><strong>Note</strong>: some of your calculated percentages may not add up to 100%. In Task 4, we reclassified only the most important categorical variables. These are known to have the greatest impact of river hydrochemistry (e.g. urban areas, farmland). While other land cover categories are found within each watershed, these typically account for only a small percentage of the total area and have a limited effect on the river environment. These categories have been excluded to simplify the analysis.</p>
<div id="an-introduction-to-linear-models-in-r" class="section level3">
<h3><span class="header-section-number">4.1.1</span> An introduction to linear models in R</h3>
<p>It is now time to examine the relationships between river water quality and catchment metrics. The key model outputs that are ultimately required for the assessment are:</p>
<ol style="list-style-type: decimal">
<li><p>Regression equations for each water quality variable (dependent variable; n = 10) and the key explanatory catchment characteristics (independent variables; n = 16).</p></li>
<li><p>Associated model values (R<sup>2</sup>, <em>p</em> value).</p></li>
</ol>
<blockquote>
<p>Remember, you don’t have to run every code block shown below, but you can do so if it would help your understanding.</p>
</blockquote>
<p>The simplest way to run a linear regression in R is to use the <code>lm()</code> function, an example of which is shown below, storing the output in <code>model</code> (you can change this name to reflect the input variables):</p>
<div class="sourceCode" id="cb66"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb66-1"><a href="mersey_five.html#cb66-1"></a><span class="co"># Fits a linear model</span></span>
<span id="cb66-2"><a href="mersey_five.html#cb66-2"></a>model &lt;-<span class="st"> </span><span class="kw">lm</span>(<span class="dt">formula =</span> NO2 <span class="op">~</span><span class="st"> </span>average_elevation, <span class="dt">data =</span> watersheds_df)</span></code></pre></div>
<p>We have defined the data frame being used (<code>data = watersheds_df</code>) and the input variables from that data frame. This is achieved by including their column names, shown here:</p>
<div class="sourceCode" id="cb67"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb67-1"><a href="mersey_five.html#cb67-1"></a><span class="kw">colnames</span>(watersheds_df)</span></code></pre></div>
<pre><code>##  [1] &quot;Seed_Point_ID&quot;          &quot;FID&quot;                    &quot;EA_ID&quot;                 
##  [4] &quot;Group&quot;                  &quot;Ph&quot;                     &quot;SSC&quot;                   
##  [7] &quot;Ca&quot;                     &quot;Mg&quot;                     &quot;NH4&quot;                   
## [10] &quot;NO3&quot;                    &quot;NO2&quot;                    &quot;TON&quot;                   
## [13] &quot;PO4&quot;                    &quot;Zn&quot;                     &quot;area&quot;                  
## [16] &quot;count&quot;                  &quot;average_elevation&quot;      &quot;average_rainfall&quot;      
## [19] &quot;average_slope&quot;          &quot;average_aspect&quot;         &quot;Arable&quot;                
## [22] &quot;Heath&quot;                  &quot;Grassland&quot;              &quot;Urban&quot;                 
## [25] &quot;Wetland&quot;                &quot;Permeable&quot;              &quot;Impermeable&quot;           
## [28] &quot;Gleyed&quot;                 &quot;Peats&quot;                  &quot;Sands_and_Muds&quot;        
## [31] &quot;Limestone&quot;              &quot;Coal&quot;                   &quot;Arable_percent&quot;        
## [34] &quot;Heath_percent&quot;          &quot;Grassland_percent&quot;      &quot;Urban_percent&quot;         
## [37] &quot;Wetland_percent&quot;        &quot;Permeable_percent&quot;      &quot;Impermeable_percent&quot;   
## [40] &quot;Gleyed_percent&quot;         &quot;Peats_percent&quot;          &quot;Sands_and_Muds_percent&quot;
## [43] &quot;Limestone_percent&quot;      &quot;Coal_percent&quot;</code></pre>
<p>Input variables in the <strong>formula</strong> are separated by <code>~</code>, where the variable to the left is the dependent variable (<code>NO2</code>) and the variable to the right is an independent variable (<code>average_elevation</code>). We can, however, include <strong>multiple</strong> independent variables to perform multiple linear regression. This is achieved as follows, where additional independent variables are separated by <code>+</code>:</p>
<div class="sourceCode" id="cb69"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb69-1"><a href="mersey_five.html#cb69-1"></a><span class="co"># Fits a linear model</span></span>
<span id="cb69-2"><a href="mersey_five.html#cb69-2"></a>model &lt;-<span class="st"> </span><span class="kw">lm</span>(<span class="dt">formula =</span> NO2 <span class="op">~</span><span class="st"> </span>average_elevation <span class="op">+</span><span class="st"> </span>average_rainfall, <span class="dt">data =</span> watersheds_df)</span></code></pre></div>
<p>We can then assess the model output using the <code>summary</code> function:</p>
<div class="sourceCode" id="cb70"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb70-1"><a href="mersey_five.html#cb70-1"></a><span class="kw">summary</span>(model)</span></code></pre></div>
<pre><code>## 
## Call:
## lm(formula = NO2 ~ average_elevation + average_rainfall, data = watersheds_df)
## 
## Residuals:
##       Min        1Q    Median        3Q       Max 
## -0.059950 -0.015188 -0.010499  0.002269  0.226625 
## 
## Coefficients:
##                     Estimate Std. Error t value Pr(&gt;|t|)   
## (Intercept)        9.525e-02  3.198e-02   2.978  0.00403 **
## average_elevation -2.096e-04  8.951e-05  -2.341  0.02220 * 
## average_rainfall  -8.358e-06  5.450e-05  -0.153  0.87857   
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 0.04402 on 67 degrees of freedom
## Multiple R-squared:  0.3109, Adjusted R-squared:  0.2903 
## F-statistic: 15.11 on 2 and 67 DF,  p-value: 3.828e-06</code></pre>
<p>For this set of independent variables, we have an R<sup>2</sup> of 0.31 (<code>Multiple R-squared: 0.3109</code>) and a model <em>p</em> value of &lt; 0.01 (<code>p-value: 3.828e-06</code>).</p>
<p>The model coefficients for the independent variables are described above, where <code>*</code> denotes <em>p</em> values &lt; 0.05 (95% probability) and <code>**</code> denotes <em>p</em> values &lt; 0.01 (99% probability). As the coefficients are very small, they are presented in scientific notation. These can be converted to numeric (non-scientific) format using the following code:</p>
<div class="sourceCode" id="cb72"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb72-1"><a href="mersey_five.html#cb72-1"></a><span class="kw">format</span>(<span class="op">-</span><span class="fl">2.096e-04</span>, <span class="dt">scientific =</span> <span class="ot">FALSE</span>)</span></code></pre></div>
<pre><code>## [1] &quot;-0.0002096&quot;</code></pre>
<p>We can supply multiple values to the <code>format</code> function by creating a vector:</p>
<div class="sourceCode" id="cb74"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb74-1"><a href="mersey_five.html#cb74-1"></a><span class="kw">format</span>(<span class="kw">c</span>(<span class="op">-</span><span class="fl">2.096e-04</span>, <span class="fl">-8.358e-06</span>, ...) , <span class="dt">scientific =</span> <span class="ot">FALSE</span>)</span></code></pre></div>
<blockquote>
<p>When you’re happy you understanding the formatting of the <code>lm</code> function, move on to the next section.</p>
</blockquote>
</div>
<div id="training-vs.-testing" class="section level3">
<h3><span class="header-section-number">4.1.2</span> Training vs. Testing</h3>
<p>One limitation of the above approach is that our dataframe (<code>watersheds_df</code>) contains observations from all 70 EA monitoring stations.</p>
<p>When performing statistical analysis, it is common practice to split any dataset into:</p>
<ul>
<li>a <strong>training</strong> subset, which is used to create the model(s).</li>
<li>a <strong>testing</strong> subset, which is used to evaluate the model(s).</li>
</ul>
<p>Subsetting our data in this way allows models to be evaluated more rigorously. Many models perform well “in-sample” but poorly “out-of-sample” when evaluated against independent data (i.e. the testing subset). This is commonly referred to as “over-fitting”.</p>
<p>Training and testing subsets are usually defined randomly, with an approximate ratio of 70:30 (although this varies). However, and to ensure reproducibility, this step has been completed for you: the <code>watersheds_df</code> dataframe contains a <code>group</code> variable denoting which monitoring sites belong to the training and testing subsets.</p>
<blockquote>
<p>Run the code above to create <code>training</code> and <code>testing</code> dataframes:</p>
</blockquote>
<div class="sourceCode" id="cb75"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb75-1"><a href="mersey_five.html#cb75-1"></a><span class="co"># Extracts training dataset, comprising 50 observations (~70%)</span></span>
<span id="cb75-2"><a href="mersey_five.html#cb75-2"></a>training &lt;-<span class="st"> </span><span class="kw">subset</span>(watersheds_df, Group <span class="op">==</span><span class="st"> &quot;Training&quot;</span>)</span>
<span id="cb75-3"><a href="mersey_five.html#cb75-3"></a></span>
<span id="cb75-4"><a href="mersey_five.html#cb75-4"></a><span class="co"># Extracts training dataset, comprising 20 observations (~30%)</span></span>
<span id="cb75-5"><a href="mersey_five.html#cb75-5"></a>testing &lt;-<span class="st"> </span><span class="kw">subset</span>(watersheds_df, Group <span class="op">==</span><span class="st"> &quot;Testing&quot;</span>) </span></code></pre></div>
<blockquote>
<p>Before you move on to the next section, can you think of any limitations of this approach?</p>
</blockquote>
<blockquote>
<p>Hints: How important is the training-testing ratio? How are training-testing subsets created?</p>
</blockquote>
</div>
<div id="variable-selection-strategies" class="section level3">
<h3><span class="header-section-number">4.1.3</span> Variable selection strategies</h3>
<p>An addition weakness of the above approach is that we have manually defined the independent variables of interest (<code>average_elevation + average_rainfall</code>). For exploratory analysis, however, we may not know which are the most important variables. Perhaps there is a combination of independent variables which produces a better model fit (e.g. R<sup>2</sup> &gt; 0.31)?</p>
<p>Determining which variables to include/exclude from a model is a very difficult problem, which has resulted in many different variable selection strategies. Common approaches include expert opinion and/or theory, partial least squares (PLS) regression, implemented in <code>PLS</code>, Least Absolute Shrinkage and Selection Operator (LASSO), implemented in <code>glmnet</code> and <code>LARS</code>, as well as elastic net methods and ridge regression, also implemented in <code>glmnet</code>. You may want to explore some of these more complex approaches for your dissertation.</p>
<p>For our analysis, we are going to use a relatively simple method known as <strong>Stepwise Regression</strong>, implemented in the <code>MASS</code> package. This works by including <strong>all</strong> the relevant independent variables in the analysis and then selecting those with the greatest explanatory power.</p>
<p>However, we don’t necessarily want to test <em>all</em> model variables. We would probably want to exclude the categorical counts (e.g. Arable, Heath, …) as these factors are already represented by the normalised variables (e.g. Arable_percent, Heath_percent, …), as well as any IDs or geometry variables (area). In general, we are only interested in testing the continuous derivatives (column names starting with <code>average_</code>) and the normalised categorical derivatives (column names ending in ’_percent’).</p>
<p>Rather than typing out the columns of interest manually, we are going to use the <code>select</code> function from the <code>dplyr</code> package to do so:</p>
<div class="sourceCode" id="cb76"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb76-1"><a href="mersey_five.html#cb76-1"></a><span class="co"># Creates a vector of column names, including only those which contain &quot;average&quot; or &quot;percent&quot;</span></span>
<span id="cb76-2"><a href="mersey_five.html#cb76-2"></a>factors &lt;-<span class="st"> </span><span class="kw">colnames</span>(watersheds_df <span class="op">%&gt;%</span><span class="st"> </span>dplyr<span class="op">::</span><span class="kw">select</span>(<span class="kw">contains</span>(<span class="kw">c</span>(<span class="st">&quot;average&quot;</span>, <span class="st">&quot;percent&quot;</span>))))</span>
<span id="cb76-3"><a href="mersey_five.html#cb76-3"></a></span>
<span id="cb76-4"><a href="mersey_five.html#cb76-4"></a><span class="co"># Prints to console</span></span>
<span id="cb76-5"><a href="mersey_five.html#cb76-5"></a>factors</span></code></pre></div>
<pre><code>##  [1] &quot;average_elevation&quot;      &quot;average_rainfall&quot;       &quot;average_slope&quot;         
##  [4] &quot;average_aspect&quot;         &quot;Arable_percent&quot;         &quot;Heath_percent&quot;         
##  [7] &quot;Grassland_percent&quot;      &quot;Urban_percent&quot;          &quot;Wetland_percent&quot;       
## [10] &quot;Permeable_percent&quot;      &quot;Impermeable_percent&quot;    &quot;Gleyed_percent&quot;        
## [13] &quot;Peats_percent&quot;          &quot;Sands_and_Muds_percent&quot; &quot;Limestone_percent&quot;     
## [16] &quot;Coal_percent&quot;</code></pre>
<blockquote>
<p>Run the above code. <strong>Note</strong>, the formatting of <code>dplyr::select</code> may be slightly confusing but it is necessary because there is also a <code>select</code> function in the <code>MASS</code> package. Here, we are telling R to use <code>select</code> from <code>dplyr</code>.</p>
</blockquote>
<p>Using this vector of column names, we are going to create a new data frame (called <code>variables</code>) containing only the independent variables of interest. <strong>Crucially</strong>, this is only for the <code>training</code> dataset:</p>
<div class="sourceCode" id="cb78"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb78-1"><a href="mersey_five.html#cb78-1"></a>variables &lt;-<span class="st"> </span>training[factors]</span></code></pre></div>
<blockquote>
<p>Run the above code and use <code>head()</code> to inspect the results.</p>
</blockquote>
<p>Next, we are going to combine this data frame (<code>cbind</code>) with a dependent variable of interest; we will use NO<sub>2</sub> as an example. Our new dataframe will be called <code>model_df</code> as it contains all the variables (dependent + independent) required for multiple linear regression. <strong>Note</strong>: by default, <code>cbind</code> will (somewhat unhelpfully) rename input column names e.g. <code>NO2</code> will become <code>watersheds_df$NO2</code>. The code below specifies the new column name as NO2 (<code>NO2 =</code>) for readability:</p>
<div class="sourceCode" id="cb79"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb79-1"><a href="mersey_five.html#cb79-1"></a><span class="co"># Column bind the NO2 column with the independent variables from the training dataset</span></span>
<span id="cb79-2"><a href="mersey_five.html#cb79-2"></a>model_df &lt;-<span class="st"> </span><span class="kw">cbind</span>(<span class="dt">NO2 =</span> training<span class="op">$</span>NO2, variables)</span></code></pre></div>
<p>When complete, we can then run a new model, making sure to update the data frame used (<code>data = model_df</code>) and updating the formula to <code>NO2 ~ .</code>. This denotes that <em>all</em> other data frame columns will be included as independent variables (a useful time saver!):</p>
<div class="sourceCode" id="cb80"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb80-1"><a href="mersey_five.html#cb80-1"></a><span class="co"># Fits a linear model, including all other columns (~.) as independent variables</span></span>
<span id="cb80-2"><a href="mersey_five.html#cb80-2"></a>no2_model &lt;-<span class="st"> </span><span class="kw">lm</span>(<span class="dt">formula =</span> NO2 <span class="op">~</span><span class="st"> </span>., <span class="dt">data =</span> model_df)</span></code></pre></div>
<blockquote>
<p>When you’re happy you understand the <code>lm</code> syntax, combine the two dataframes, run the linear model and inspect the output using <code>summary()</code>. This should resemble the following:</p>
</blockquote>
<pre><code>## 
## Call:
## lm(formula = NO2 ~ ., data = model_df)
## 
## Residuals:
##      Min       1Q   Median       3Q      Max 
## -0.05094 -0.01581  0.00000  0.01189  0.07890 
## 
## Coefficients:
##                          Estimate Std. Error t value Pr(&gt;|t|)  
## (Intercept)            -1.488e-01  1.541e+00  -0.097   0.9237  
## average_elevation       2.101e-04  2.093e-04   1.004   0.3227  
## average_rainfall        7.235e-05  8.240e-05   0.878   0.3863  
## average_slope          -1.432e-02  7.764e-03  -1.844   0.0741 .
## average_aspect          8.238e-05  1.734e-04   0.475   0.6379  
## Arable_percent         -3.115e-05  8.696e-04  -0.036   0.9716  
## Heath_percent          -6.940e-04  1.157e-03  -0.600   0.5526  
## Grassland_percent      -6.541e-04  8.737e-04  -0.749   0.4594  
## Urban_percent           5.643e-04  9.223e-04   0.612   0.5449  
## Wetland_percent        -5.993e-04  1.020e-03  -0.588   0.5608  
## Permeable_percent       2.498e-03  1.496e-02   0.167   0.8684  
## Impermeable_percent     1.755e-03  1.489e-02   0.118   0.9069  
## Gleyed_percent          2.198e-03  1.495e-02   0.147   0.8840  
## Peats_percent           2.075e-03  1.503e-02   0.138   0.8911  
## Sands_and_Muds_percent -4.969e-04  3.784e-03  -0.131   0.8963  
## Limestone_percent       9.282e-05  3.982e-03   0.023   0.9815  
## Coal_percent           -7.355e-04  3.790e-03  -0.194   0.8473  
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 0.03511 on 33 degrees of freedom
## Multiple R-squared:  0.5481, Adjusted R-squared:  0.329 
## F-statistic: 2.502 on 16 and 33 DF,  p-value: 0.0127</code></pre>
<p>Our overall model fit (R<sup>2</sup>) is 0.55 which indicates that the independent variables explain ~55% of variability in the dependent variable. However, the model contains many independent variables which are not statistically significant, here defined as having a <em>p</em> value &gt; 0.05.</p>
<p>This number represents the probability that the result has occurred by chance. When values are very small (e.g. <em>p</em> &lt; 0.0005), we would typically present these as a discrete value e.g. <em>p</em> &lt; 0.05, &lt; 0.01, &lt; 0.001. Generally, we only use models in which we can be 95% confident or higher (i.e. significance level of 0.05 or less).</p>
<p>However, it is important to note that <em>p</em> values should be not be considered in isolation and need to be interpreted carefully. For statistical reviews of using and interpreting <em>p</em> values, see <span class="citation">Goodman (<a href="#ref-goodman_dirty_2008" role="doc-biblioref">2008</a>)</span> and <span class="citation">Andrade (<a href="#ref-andrade_p_2019" role="doc-biblioref">2019</a>)</span>. For a broader overview, see the <em>Nature</em> commentary by <span class="citation">Amrhein <em>et al.</em> (<a href="#ref-amrhein_scientists_2019" role="doc-biblioref">2019</a>)</span>, as well as a summary article by <a href="https://www.vox.com/latest-news/2019/3/22/18275913/statistical-significance-p-values-explained">Vox</a>.</p>
<p>To filter our independent variables to include only the most important, we can use the <code>step.AIC</code> function from the <code>MASS</code> library as follows:</p>
<div class="sourceCode" id="cb82"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb82-1"><a href="mersey_five.html#cb82-1"></a><span class="co"># Stepwise regression model</span></span>
<span id="cb82-2"><a href="mersey_five.html#cb82-2"></a>step.model &lt;-<span class="st"> </span><span class="kw">stepAIC</span>(no2_model, <span class="co"># Input linear model</span></span>
<span id="cb82-3"><a href="mersey_five.html#cb82-3"></a>                      <span class="dt">direction =</span> <span class="st">&quot;both&quot;</span>,</span>
<span id="cb82-4"><a href="mersey_five.html#cb82-4"></a>                      <span class="dt">trace =</span> <span class="ot">FALSE</span>, <span class="co"># Print out intermediate results? </span></span>
<span id="cb82-5"><a href="mersey_five.html#cb82-5"></a>                      <span class="dt">k =</span> <span class="dv">1</span>) </span></code></pre></div>
<p>Helpfully, this takes the output of the <code>lm</code> model (<code>no2_model</code>) with no need for any additional data wrangling. The following are important parameters:</p>
<ul>
<li><code>direction = "both"</code>:
<ul>
<li>Determines the method used, either <strong>forward</strong> or <strong>backward</strong> stepwise regression, or a mixture of <strong>both</strong>.</li>
<li>“Forward” begins with a model with <strong>no</strong> variables and then starts adding the most significant variables, stopping when there are no more significant variables.</li>
<li>“Backward” begins with a model with <strong>all</strong> variables and then starts removing the least significant variables, stopping when only significant variables are remaining.</li>
<li>“Both” includes both of the above, allowing for variables to be added/removed at each step.</li>
</ul></li>
<li><code>k = 1</code>:
<ul>
<li>The number of degrees of freedom used for the penalty i.e. for determining whether variables are significant or not.</li>
</ul></li>
</ul>
<blockquote>
<p>Run the above model (<code>direction = "both"</code> and <code>k = 1</code>) and print the output using <code>summary()</code>:</p>
</blockquote>
<pre><code>## 
## Call:
## lm(formula = NO2 ~ average_elevation + average_rainfall + average_slope + 
##     Urban_percent + Permeable_percent + Coal_percent, data = model_df)
## 
## Residuals:
##       Min        1Q    Median        3Q       Max 
## -0.055272 -0.015115 -0.003007  0.015961  0.084550 
## 
## Coefficients:
##                     Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept)        6.584e-04  3.927e-02   0.017 0.986701    
## average_elevation  1.594e-04  1.497e-04   1.065 0.292790    
## average_rainfall   6.196e-05  6.626e-05   0.935 0.354980    
## average_slope     -1.400e-02  6.255e-03  -2.239 0.030399 *  
## Urban_percent      1.122e-03  3.093e-04   3.628 0.000753 ***
## Permeable_percent  3.384e-04  2.054e-04   1.648 0.106710    
## Coal_percent      -2.648e-04  1.855e-04  -1.428 0.160617    
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 0.0315 on 43 degrees of freedom
## Multiple R-squared:  0.526,  Adjusted R-squared:  0.4598 
## F-statistic: 7.952 on 6 and 43 DF,  p-value: 8.487e-06</code></pre>
<p>As you can see above, using a low threshold for the degrees of freedom (<code>k = 1</code>) means we still have many “non-significant” variables remaining (<em>p</em> &gt; 0.05)</p>
<blockquote>
<p>Re-run the above model, but increasing the value of <code>k</code> in intervals of 1 until all the independent variables are significant at <em>p</em> = 0.05 (denoted by <code>*</code>):</p>
</blockquote>
<pre><code>## 
## Call:
## lm(formula = NO2 ~ average_slope + Urban_percent, data = model_df)
## 
## Residuals:
##       Min        1Q    Median        3Q       Max 
## -0.054050 -0.020404 -0.004278  0.012876  0.098725 
## 
## Coefficients:
##                 Estimate Std. Error t value Pr(&gt;|t|)   
## (Intercept)    0.0435188  0.0125665   3.463  0.00115 **
## average_slope -0.0040031  0.0016679  -2.400  0.02040 * 
## Urban_percent  0.0009819  0.0002977   3.299  0.00186 **
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 0.03169 on 47 degrees of freedom
## Multiple R-squared:  0.4756, Adjusted R-squared:  0.4533 
## F-statistic: 21.31 on 2 and 47 DF,  p-value: 2.582e-07</code></pre>
<p>In general, we prefer models with the minimum number of parameters (independent variables). They require fewer assumptions, less intensive data collection and can be applied more confidently to new data sets/locations. This principle of model parsimony is based upon <strong>Occam’s Razor</strong>: “other things being equal, simpler explanations are generally better than more complex ones”.</p>
<p>Our original model, based upon 16 independent variables had an R<sup>2</sup> of 0.55. This new model, based upon just 2 independent variables (<code>average_slope + Urban_percent</code>) has an R<sup>2</sup> of 0.48; a relatively minor reduction in explanatory power given the removal of 14 (arguably unimportant) additional variables.</p>
<p>Our model coefficients are now as follows:</p>
<ul>
<li><code>intercept</code> = 0.0435188, <em>p</em> = 0.00115 (<em>p</em> &lt; 0.01)</li>
<li><code>average_slope</code> = -0.0040031, <em>p</em> = 0.02040 (<em>p</em> &lt; 0.05)</li>
<li><code>Urban_percent</code> = 0.0009819, <em>p</em> = 0.00186 (<em>p</em> &lt; 0.01)</li>
</ul>
<p>Coefficients are important because they are used in <strong>regression equations</strong>, which can then be used to predict values.</p>
<p>The general format for a regression equation is as follows:</p>
<p><span class="math display">\[
y = a + (b_1 \cdot x_1) + (b_2 \cdot x_2) + (b_n \cdot x_n)
\]</span>
where <code>a</code> is the constant (intercept) value, and <code>b</code> is the coefficient of x.</p>
<p>For our NO<sub>2</sub> model above, we can define our regression equation (presented using sensible data precision) as:</p>
<p><span class="math display">\[
NO_2 = 0.044 + (0.001 \cdot Urban \: percent) + (-0.004 \cdot Average \: slope)
\]</span>
<strong>Well done!</strong> You have now calculated a regression which links the dependent variable (NO<sub>2</sub>) to a set of independent variables, in the case the average slope of the watershed and the percentage urban land cover.</p>
<blockquote>
<p>For your assessment, we would like you to <strong>explain</strong> the regression results, linking to hydrological processes and literature. Think about specific sources of pollution, transport pathways, types of flow…</p>
</blockquote>
</div>
</div>
<div id="task-8-model-evaluation" class="section level2">
<h2><span class="header-section-number">4.2</span> Task 8: Model evaluation</h2>
<p>Having created a statistical model, it is necessary to evaluate its performance. Comparison plots of <strong>measured vs. modelled (or predicted) values</strong> are one common way to assess model quality, alongside other metrics such as root-mean-square error (RMSE), normalised root-mean-square-error (nRMSE), Q-Q plots, or histograms of model residuals. You may want to explore some of these for the assessment.</p>
<p>To calculate modelled values, we can use the <code>predict()</code> function, taking the model variable (<code>step.model</code>) as the input, rather than re-creating the above equation manually in code, and using our <code>testing</code> dataframe for the <code>newdata</code> argument:</p>
<div class="sourceCode" id="cb85"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb85-1"><a href="mersey_five.html#cb85-1"></a><span class="co"># Predict NO2 values based upon stepwise model, saving to testing dataframe</span></span>
<span id="cb85-2"><a href="mersey_five.html#cb85-2"></a>testing<span class="op">$</span>predicted_no2 &lt;-<span class="st"> </span><span class="kw">predict</span>(step.model, <span class="dt">newdata =</span> testing)</span></code></pre></div>
<p>If<code>new_data</code> is not defined, the <code>predict</code> function uses the fitted values for prediction i.e. the training data used to construct the model (see <a href="https://www.rdocumentation.org/packages/stats/versions/3.6.2/topics/predict.lm">here</a>).</p>
<blockquote>
<p>Run the above code block to predict NO<sub>2</sub> concentrations in the testing dataset, based on the regression model produced from the training dataset.</p>
</blockquote>
<p>These values could be used to calculate RMSE or other metrics (nRMSE) using your own code or additional packages (e.g. <code>Metrics</code>);</p>
<p><span class="math display">\[
 RMSE = \sqrt{mean(measured\:values - modelled\:values)^2}
\]</span></p>
<p>Plots of measured vs. modelled values (as well as Q-Q plots and histograms) can be created in ggplot2. Here is an example:</p>
<div class="sourceCode" id="cb86"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb86-1"><a href="mersey_five.html#cb86-1"></a><span class="co"># ggplot of measured vs. modelled (predicted) NO2 values</span></span>
<span id="cb86-2"><a href="mersey_five.html#cb86-2"></a>no2_plot &lt;-<span class="st"> </span><span class="kw">ggplot</span>(<span class="dt">data =</span> testing, <span class="kw">aes</span>(<span class="dt">x =</span> NO2, <span class="dt">y =</span> predicted_no2)) <span class="op">+</span></span>
<span id="cb86-3"><a href="mersey_five.html#cb86-3"></a><span class="st">  </span><span class="co"># Adding a linear regression (&quot;lm&quot;), removing standard error bars (se = FALSE)</span></span>
<span id="cb86-4"><a href="mersey_five.html#cb86-4"></a><span class="st">  </span><span class="kw">geom_smooth</span>(<span class="dt">method =</span> <span class="st">&quot;lm&quot;</span>, <span class="dt">se =</span> <span class="ot">FALSE</span>, <span class="dt">colour=</span><span class="st">&quot;#FF953C&quot;</span>) <span class="op">+</span></span>
<span id="cb86-5"><a href="mersey_five.html#cb86-5"></a><span class="st">  </span><span class="co"># Adds a 1:1 line for comparison</span></span>
<span id="cb86-6"><a href="mersey_five.html#cb86-6"></a><span class="st">  </span><span class="kw">geom_abline</span>(<span class="dt">intercept =</span> <span class="dv">0</span>, <span class="dt">slope =</span> <span class="dv">1</span>, <span class="dt">lty =</span> <span class="st">&quot;dashed&quot;</span>) <span class="op">+</span></span>
<span id="cb86-7"><a href="mersey_five.html#cb86-7"></a><span class="st">  </span><span class="co"># Adds the point data, modifying the shape, size, colour and fill</span></span>
<span id="cb86-8"><a href="mersey_five.html#cb86-8"></a><span class="st">  </span><span class="kw">geom_point</span>(<span class="dt">shape =</span> <span class="dv">21</span>, <span class="dt">colour =</span> <span class="st">&quot;white&quot;</span>, <span class="dt">fill =</span> <span class="st">&quot;#5695FF&quot;</span>, <span class="dt">size =</span> <span class="fl">2.5</span>) <span class="op">+</span></span>
<span id="cb86-9"><a href="mersey_five.html#cb86-9"></a><span class="st">  </span><span class="co"># Setting the theme and aspect ratio</span></span>
<span id="cb86-10"><a href="mersey_five.html#cb86-10"></a><span class="st">  </span><span class="kw">theme_classic</span>() <span class="op">+</span></span>
<span id="cb86-11"><a href="mersey_five.html#cb86-11"></a><span class="st">  </span><span class="kw">theme</span>(<span class="dt">aspect.ratio =</span> <span class="dv">1</span>) <span class="op">+</span></span>
<span id="cb86-12"><a href="mersey_five.html#cb86-12"></a><span class="st">  </span><span class="co"># Axis limits</span></span>
<span id="cb86-13"><a href="mersey_five.html#cb86-13"></a><span class="st">  </span><span class="kw">scale_x_continuous</span>(<span class="dt">limits =</span> <span class="kw">c</span>(<span class="dv">0</span>,<span class="fl">0.3</span>)) <span class="op">+</span></span>
<span id="cb86-14"><a href="mersey_five.html#cb86-14"></a><span class="st">  </span><span class="kw">scale_y_continuous</span>(<span class="dt">limits =</span> <span class="kw">c</span>(<span class="dv">0</span>,<span class="fl">0.3</span>)) <span class="op">+</span></span>
<span id="cb86-15"><a href="mersey_five.html#cb86-15"></a><span class="st">  </span><span class="co"># Add axis labels and a title</span></span>
<span id="cb86-16"><a href="mersey_five.html#cb86-16"></a><span class="st">  </span><span class="kw">labs</span>(<span class="dt">x =</span> Measured<span class="op">~</span>NO[<span class="dv">2</span>], <span class="dt">y =</span> Modelled<span class="op">~</span>NO[<span class="dv">2</span>], </span>
<span id="cb86-17"><a href="mersey_five.html#cb86-17"></a>       <span class="dt">title =</span> Plot<span class="op">~</span>of<span class="op">~</span>measured<span class="op">~</span>vs.<span class="op">~</span>modelled<span class="op">~</span>NO[<span class="dv">2</span>]<span class="op">~</span>values)</span>
<span id="cb86-18"><a href="mersey_five.html#cb86-18"></a></span>
<span id="cb86-19"><a href="mersey_five.html#cb86-19"></a>no2_plot</span></code></pre></div>
<p><img src="Practical_1_files/figure-html/unnamed-chunk-67-1.png" width="672" style="display: block; margin: auto;" /></p>
<blockquote>
<p>Does the regression line match the 1:1 line? Is there any evidence of under- or over-prediction? Are there any outliers? What <strong>types</strong> of errors can you identify?</p>
</blockquote>
<p>You could also assess this relationship statistically, using linear regression:</p>
<div class="sourceCode" id="cb87"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb87-1"><a href="mersey_five.html#cb87-1"></a><span class="co"># Linear regression of measured vs. modelled NO2 values</span></span>
<span id="cb87-2"><a href="mersey_five.html#cb87-2"></a>prediction_model &lt;-<span class="st"> </span><span class="kw">lm</span>(<span class="dt">formula =</span> NO2 <span class="op">~</span><span class="st"> </span>predicted_no2, <span class="dt">data =</span> testing)</span>
<span id="cb87-3"><a href="mersey_five.html#cb87-3"></a></span>
<span id="cb87-4"><a href="mersey_five.html#cb87-4"></a><span class="co"># Print summary statistics</span></span>
<span id="cb87-5"><a href="mersey_five.html#cb87-5"></a><span class="kw">summary</span>(prediction_model)</span></code></pre></div>
<pre><code>## 
## Call:
## lm(formula = NO2 ~ predicted_no2, data = testing)
## 
## Residuals:
##       Min        1Q    Median        3Q       Max 
## -0.084244 -0.027091  0.000268  0.011034  0.151937 
## 
## Coefficients:
##               Estimate Std. Error t value Pr(&gt;|t|)   
## (Intercept)    -0.0155     0.0232  -0.668  0.51244   
## predicted_no2   1.7953     0.4705   3.816  0.00127 **
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 0.05418 on 18 degrees of freedom
## Multiple R-squared:  0.4472, Adjusted R-squared:  0.4165 
## F-statistic: 14.56 on 1 and 18 DF,  p-value: 0.001265</code></pre>
<blockquote>
<p>How well does our NO<sub>2</sub> model perform on the testing dataset, based on the above graphs/statistics? Is out-of-sample performance comparable to in-sample performance?</p>
</blockquote>
<p><br/></p>
<p><strong>To finish the practical</strong> and to prepare for the assessment:</p>
<blockquote>
<p>Replicating the above approaches, calculate regression equations based on stepwise linear regression for all 10 water quality indicators (NO<sub>2</sub>, pH, SSC, Ca, Mg, NH<sub>4</sub>, NO<sub>3</sub>, TON, PO<sub>4</sub>, Zn).</p>
</blockquote>
<blockquote>
<p>Use the same approach to create new data frames for each indicator, remembering to update the <code>k</code> parameter in the <code>step.AIC</code> function (beginning at <code>k = 1</code>) to determine the statistically significant variables.</p>
</blockquote>
<blockquote>
<p>Save the relevant model coefficients and the R<sup>2</sup> and <em>p</em> values for each equation. These should be stored in a single table for the assessment.</p>
</blockquote>

<div id="refs" class="references">
<div>
<p>Amrhein, V. <em>et al.</em> (2019) ‘Scientists rise up against statistical significance’, <em>Nature</em>, 567(7748), pp. 305–307. doi:<a href="https://doi.org/10.1038/d41586-019-00857-9">10.1038/d41586-019-00857-9</a>.</p>
</div>
<div>
<p>Andrade, C. (2019) ‘The P Value and Statistical Significance: Misunderstandings, Explanations, Challenges, and Alternatives’, <em>Indian Journal of Psychological Medicine</em>, 41(3), pp. 210–215. doi:<a href="https://doi.org/10.4103/IJPSYM.IJPSYM_193_19">10.4103/IJPSYM.IJPSYM_193_19</a>.</p>
</div>
<div>
<p>Goodman, S. (2008) ‘A Dirty Dozen: Twelve P-Value Misconceptions’, <em>Seminars in Hematology</em>, 45(3), pp. 135–140. doi:<a href="https://doi.org/10.1053/j.seminhematol.2008.04.003">10.1053/j.seminhematol.2008.04.003</a>.</p>
</div>
</div>
</div>
</div>






<h3>References</h3>
<div id="refs" class="references">
<div id="ref-amrhein_scientists_2019">
<p>Amrhein, V. <em>et al.</em> (2019) ‘Scientists rise up against statistical significance’, <em>Nature</em>, 567(7748), pp. 305–307. doi:<a href="https://doi.org/10.1038/d41586-019-00857-9">10.1038/d41586-019-00857-9</a>.</p>
</div>
<div id="ref-andrade_p_2019">
<p>Andrade, C. (2019) ‘The P Value and Statistical Significance: Misunderstandings, Explanations, Challenges, and Alternatives’, <em>Indian Journal of Psychological Medicine</em>, 41(3), pp. 210–215. doi:<a href="https://doi.org/10.4103/IJPSYM.IJPSYM_193_19">10.4103/IJPSYM.IJPSYM_193_19</a>.</p>
</div>
<div id="ref-goodman_dirty_2008">
<p>Goodman, S. (2008) ‘A Dirty Dozen: Twelve P-Value Misconceptions’, <em>Seminars in Hematology</em>, 45(3), pp. 135–140. doi:<a href="https://doi.org/10.1053/j.seminhematol.2008.04.003">10.1053/j.seminhematol.2008.04.003</a>.</p>
</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="Intro_to_R.html" class="navigation navigation-prev navigation-unique" aria-label="Previous page"><i class="fa fa-angle-left"></i></a>

    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"whatsapp": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": null,
"text": null
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": null,
"search": {
"engine": "lunr",
"options": null
},
"toc": {
"collapse": "section"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
