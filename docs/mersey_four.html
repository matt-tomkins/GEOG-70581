<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>Chapter 11 Mersey IV - Statistical analysis |  Hydrological analysis in R </title>
  <meta name="description" content="<br />
Hydrological analysis in R<br />
</center>" />
  <meta name="generator" content="bookdown 0.43 and GitBook 2.6.7" />

  <meta property="og:title" content="Chapter 11 Mersey IV - Statistical analysis |  Hydrological analysis in R " />
  <meta property="og:type" content="book" />
  
  
  

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Chapter 11 Mersey IV - Statistical analysis |  Hydrological analysis in R " />
  
  
  




  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="mersey_bonus.html"/>
<link rel="next" href="Hints.html"/>
<script src="libs/jquery-3.6.0/jquery-3.6.0.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/fuse.js@6.4.6/dist/fuse.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />








<link href="libs/anchor-sections-1.1.0/anchor-sections.css" rel="stylesheet" />
<link href="libs/anchor-sections-1.1.0/anchor-sections-hash.css" rel="stylesheet" />
<script src="libs/anchor-sections-1.1.0/anchor-sections.js"></script>
<link href="libs/htmltools-fill-0.5.8.1/fill.css" rel="stylesheet" />
<script src="libs/htmlwidgets-1.6.4/htmlwidgets.js"></script>
<link href="libs/leaflet-1.3.1/leaflet.css" rel="stylesheet" />
<script src="libs/leaflet-1.3.1/leaflet.js"></script>
<link href="libs/leafletfix-1.0.0/leafletfix.css" rel="stylesheet" />
<script src="libs/proj4-2.6.2/proj4.min.js"></script>
<script src="libs/Proj4Leaflet-1.0.1/proj4leaflet.js"></script>
<link href="libs/rstudio_leaflet-1.3.1/rstudio_leaflet.css" rel="stylesheet" />
<script src="libs/leaflet-binding-2.2.2/leaflet.js"></script>
<script src="libs/leaflet-providers-2.0.0/leaflet-providers_2.0.0.js"></script>
<script src="libs/leaflet-providers-plugin-2.2.2/leaflet-providers-plugin.js"></script>


<style type="text/css">
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { display: inline-block; text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { color: #008000; } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { color: #008000; font-weight: bold; } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>

<style type="text/css">
  
  div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
</style>
<style type="text/css">
/* Used with Pandoc 2.11+ new --citeproc when CSL is used */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
}
.hanging div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}
</style>

</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<div style="text-align: center; margin: 1em 0;">
  <img src="images/course-logo.png" width="200">
</div>

<li class="divider"></li>
<li class="part"><span><b>Home</b></span></li>
<li class="chapter" data-level="1" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i><b>1</b> Introduction</a>
<ul>
<li class="chapter" data-level="1.1" data-path="index.html"><a href="index.html#practical-outline"><i class="fa fa-check"></i><b>1.1</b> Practical outline</a></li>
<li class="chapter" data-level="1.2" data-path="index.html"><a href="index.html#objectives"><i class="fa fa-check"></i><b>1.2</b> Objectives</a></li>
<li class="chapter" data-level="1.3" data-path="index.html"><a href="index.html#schedule"><i class="fa fa-check"></i><b>1.3</b> Schedule</a></li>
</ul></li>
<li class="chapter" data-level="2" data-path="Installation.html"><a href="Installation.html"><i class="fa fa-check"></i><b>2</b> Installation</a>
<ul>
<li class="chapter" data-level="2.1" data-path="Installation.html"><a href="Installation.html#r"><i class="fa fa-check"></i><b>2.1</b> R</a></li>
<li class="chapter" data-level="2.2" data-path="Installation.html"><a href="Installation.html#r-studio"><i class="fa fa-check"></i><b>2.2</b> R Studio</a></li>
<li class="chapter" data-level="2.3" data-path="Installation.html"><a href="Installation.html#materials"><i class="fa fa-check"></i><b>2.3</b> Course materials</a></li>
</ul></li>
<li class="part"><span><b>Programming</b></span></li>
<li class="chapter" data-level="3" data-path="Intro_to_R.html"><a href="Intro_to_R.html"><i class="fa fa-check"></i><b>3</b> A (brief) introduction to R</a>
<ul>
<li class="chapter" data-level="3.1" data-path="Intro_to_R.html"><a href="Intro_to_R.html#overview"><i class="fa fa-check"></i><b>3.1</b> Overview</a>
<ul>
<li class="chapter" data-level="3.1.1" data-path="Intro_to_R.html"><a href="Intro_to_R.html#what-is-r"><i class="fa fa-check"></i><b>3.1.1</b> What is R?</a></li>
<li class="chapter" data-level="3.1.2" data-path="Intro_to_R.html"><a href="Intro_to_R.html#why_code"><i class="fa fa-check"></i><b>3.1.2</b> Why code?</a></li>
<li class="chapter" data-level="3.1.3" data-path="Intro_to_R.html"><a href="Intro_to_R.html#a-quick-note-on-the-practicals"><i class="fa fa-check"></i><b>3.1.3</b> A quick note on the practicals</a></li>
<li class="chapter" data-level="3.1.4" data-path="Intro_to_R.html"><a href="Intro_to_R.html#dealing-with-errors"><i class="fa fa-check"></i><b>3.1.4</b> Dealing with errors</a></li>
</ul></li>
<li class="chapter" data-level="3.2" data-path="Intro_to_R.html"><a href="Intro_to_R.html#loading-r"><i class="fa fa-check"></i><b>3.2</b> Loading R</a></li>
<li class="chapter" data-level="3.3" data-path="Intro_to_R.html"><a href="Intro_to_R.html#variables-looping"><i class="fa fa-check"></i><b>3.3</b> Objects</a>
<ul>
<li class="chapter" data-level="3.3.1" data-path="Intro_to_R.html"><a href="Intro_to_R.html#object-names"><i class="fa fa-check"></i><b>3.3.1</b> Object names</a></li>
<li class="chapter" data-level="3.3.2" data-path="Intro_to_R.html"><a href="Intro_to_R.html#variables_types"><i class="fa fa-check"></i><b>3.3.2</b> Object types</a></li>
</ul></li>
<li class="chapter" data-level="3.4" data-path="Intro_to_R.html"><a href="Intro_to_R.html#data-structures"><i class="fa fa-check"></i><b>3.4</b> Data structures</a>
<ul>
<li class="chapter" data-level="3.4.1" data-path="Intro_to_R.html"><a href="Intro_to_R.html#vectors"><i class="fa fa-check"></i><b>3.4.1</b> Vectors</a></li>
<li class="chapter" data-level="3.4.2" data-path="Intro_to_R.html"><a href="Intro_to_R.html#data_frames"><i class="fa fa-check"></i><b>3.4.2</b> Data frames</a></li>
</ul></li>
<li class="chapter" data-level="3.5" data-path="Intro_to_R.html"><a href="Intro_to_R.html#scripts"><i class="fa fa-check"></i><b>3.5</b> Scripts</a>
<ul>
<li class="chapter" data-level="3.5.1" data-path="Intro_to_R.html"><a href="Intro_to_R.html#comments"><i class="fa fa-check"></i><b>3.5.1</b> Comments</a></li>
</ul></li>
<li class="chapter" data-level="3.6" data-path="Intro_to_R.html"><a href="Intro_to_R.html#packages"><i class="fa fa-check"></i><b>3.6</b> Loading packages</a></li>
<li class="chapter" data-level="3.7" data-path="Intro_to_R.html"><a href="Intro_to_R.html#data_loading"><i class="fa fa-check"></i><b>3.7</b> Loading data</a></li>
<li class="chapter" data-level="3.8" data-path="Intro_to_R.html"><a href="Intro_to_R.html#data_plotting"><i class="fa fa-check"></i><b>3.8</b> Plotting</a></li>
<li class="chapter" data-level="3.9" data-path="Intro_to_R.html"><a href="Intro_to_R.html#formative_task"><i class="fa fa-check"></i><b>3.9</b> Formative task</a>
<ul>
<li class="chapter" data-level="3.9.1" data-path="Intro_to_R.html"><a href="Intro_to_R.html#formative_solution_one"><i class="fa fa-check"></i><b>3.9.1</b> Formative solution</a></li>
</ul></li>
</ul></li>
<li class="part"><span><b>Eskdale</b></span></li>
<li class="chapter" data-level="4" data-path="FirstPractical.html"><a href="FirstPractical.html"><i class="fa fa-check"></i><b>4</b> Eskdale I - Introduction</a>
<ul>
<li class="chapter" data-level="4.1" data-path="FirstPractical.html"><a href="FirstPractical.html#overview-1"><i class="fa fa-check"></i><b>4.1</b> Overview</a>
<ul>
<li class="chapter" data-level="4.1.1" data-path="FirstPractical.html"><a href="FirstPractical.html#intended-learning-outcomes"><i class="fa fa-check"></i><b>4.1.1</b> Intended learning outcomes</a></li>
<li class="chapter" data-level="4.1.2" data-path="FirstPractical.html"><a href="FirstPractical.html#assessment"><i class="fa fa-check"></i><b>4.1.2</b> Assessment</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="5" data-path="Eskdale_set_up.html"><a href="Eskdale_set_up.html"><i class="fa fa-check"></i><b>5</b> Eskdale II - Set-up</a>
<ul>
<li class="chapter" data-level="5.1" data-path="Eskdale_set_up.html"><a href="Eskdale_set_up.html#install-programs"><i class="fa fa-check"></i><b>5.1</b> Install programs</a></li>
<li class="chapter" data-level="5.2" data-path="Eskdale_set_up.html"><a href="Eskdale_set_up.html#download_data"><i class="fa fa-check"></i><b>5.2</b> Download data</a></li>
<li class="chapter" data-level="5.3" data-path="Eskdale_set_up.html"><a href="Eskdale_set_up.html#open-rstudio"><i class="fa fa-check"></i><b>5.3</b> Open RStudio</a></li>
<li class="chapter" data-level="5.4" data-path="Eskdale_set_up.html"><a href="Eskdale_set_up.html#R_Projects"><i class="fa fa-check"></i><b>5.4</b> Initialise an R project</a></li>
<li class="chapter" data-level="5.5" data-path="Eskdale_set_up.html"><a href="Eskdale_set_up.html#creating-an-r-script"><i class="fa fa-check"></i><b>5.5</b> Creating an R script</a></li>
<li class="chapter" data-level="5.6" data-path="Eskdale_set_up.html"><a href="Eskdale_set_up.html#install-whiteboxtools"><i class="fa fa-check"></i><b>5.6</b> Install WhiteboxTools</a></li>
<li class="chapter" data-level="5.7" data-path="Eskdale_set_up.html"><a href="Eskdale_set_up.html#loading-packages"><i class="fa fa-check"></i><b>5.7</b> Loading packages</a></li>
</ul></li>
<li class="chapter" data-level="6" data-path="Eskdale_flow_algorithms.html"><a href="Eskdale_flow_algorithms.html"><i class="fa fa-check"></i><b>6</b> Eskdale III - Flow routing</a>
<ul>
<li class="chapter" data-level="6.1" data-path="Eskdale_flow_algorithms.html"><a href="Eskdale_flow_algorithms.html#dem-pre-processing-flow-enforcement"><i class="fa fa-check"></i><b>6.1</b> DEM pre-processing: flow enforcement</a>
<ul>
<li class="chapter" data-level="6.1.1" data-path="Eskdale_flow_algorithms.html"><a href="Eskdale_flow_algorithms.html#data-description"><i class="fa fa-check"></i><b>6.1.1</b> Data description</a></li>
<li class="chapter" data-level="6.1.2" data-path="Eskdale_flow_algorithms.html"><a href="Eskdale_flow_algorithms.html#breaching-and-filling"><i class="fa fa-check"></i><b>6.1.2</b> Breaching and filling</a></li>
<li class="chapter" data-level="6.1.3" data-path="Eskdale_flow_algorithms.html"><a href="Eskdale_flow_algorithms.html#choosing-a-colour-ramp"><i class="fa fa-check"></i><b>6.1.3</b> Choosing a colour ramp</a></li>
</ul></li>
<li class="chapter" data-level="6.2" data-path="Eskdale_flow_algorithms.html"><a href="Eskdale_flow_algorithms.html#flow-parameters-pointers"><i class="fa fa-check"></i><b>6.2</b> Flow Parameters: Pointers</a></li>
<li class="chapter" data-level="6.3" data-path="Eskdale_flow_algorithms.html"><a href="Eskdale_flow_algorithms.html#flow-algorithms"><i class="fa fa-check"></i><b>6.3</b> Flow Algorithms</a>
<ul>
<li class="chapter" data-level="6.3.1" data-path="Eskdale_flow_algorithms.html"><a href="Eskdale_flow_algorithms.html#comparing-flow-algorithms"><i class="fa fa-check"></i><b>6.3.1</b> Comparing flow algorithms</a></li>
<li class="chapter" data-level="6.3.2" data-path="Eskdale_flow_algorithms.html"><a href="Eskdale_flow_algorithms.html#fd8-catchment-area"><i class="fa fa-check"></i><b>6.3.2</b> FD8 catchment area</a></li>
<li class="chapter" data-level="6.3.3" data-path="Eskdale_flow_algorithms.html"><a href="Eskdale_flow_algorithms.html#d-infinity-catchment-area"><i class="fa fa-check"></i><b>6.3.3</b> D-infinity catchment area</a></li>
<li class="chapter" data-level="6.3.4" data-path="Eskdale_flow_algorithms.html"><a href="Eskdale_flow_algorithms.html#comparing-the-outputs"><i class="fa fa-check"></i><b>6.3.4</b> Comparing the outputs</a></li>
</ul></li>
<li class="chapter" data-level="6.4" data-path="Eskdale_flow_algorithms.html"><a href="Eskdale_flow_algorithms.html#practical-solution"><i class="fa fa-check"></i><b>6.4</b> Practical solution</a></li>
</ul></li>
<li class="part"><span><b>Mersey</b></span></li>
<li class="chapter" data-level="7" data-path="SecondPractical.html"><a href="SecondPractical.html"><i class="fa fa-check"></i><b>7</b> Mersey I - Introduction</a>
<ul>
<li class="chapter" data-level="7.1" data-path="SecondPractical.html"><a href="SecondPractical.html#overview-2"><i class="fa fa-check"></i><b>7.1</b> Overview</a>
<ul>
<li class="chapter" data-level="7.1.1" data-path="SecondPractical.html"><a href="SecondPractical.html#topics-covered-in-this-practical"><i class="fa fa-check"></i><b>7.1.1</b> Topics covered in this practical</a></li>
<li class="chapter" data-level="7.1.2" data-path="SecondPractical.html"><a href="SecondPractical.html#intended-learning-outcomes-1"><i class="fa fa-check"></i><b>7.1.2</b> Intended Learning Outcomes</a></li>
<li class="chapter" data-level="7.1.3" data-path="SecondPractical.html"><a href="SecondPractical.html#assessment-1"><i class="fa fa-check"></i><b>7.1.3</b> Assessment</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="8" data-path="Mersey_set_up.html"><a href="Mersey_set_up.html"><i class="fa fa-check"></i><b>8</b> Mersey II - Set-up</a>
<ul>
<li class="chapter" data-level="8.1" data-path="Mersey_set_up.html"><a href="Mersey_set_up.html#practical-overview"><i class="fa fa-check"></i><b>8.1</b> Practical overview</a></li>
<li class="chapter" data-level="8.2" data-path="Mersey_set_up.html"><a href="Mersey_set_up.html#install-programs-1"><i class="fa fa-check"></i><b>8.2</b> Install programs</a></li>
<li class="chapter" data-level="8.3" data-path="Mersey_set_up.html"><a href="Mersey_set_up.html#download_data_v2"><i class="fa fa-check"></i><b>8.3</b> Download data</a></li>
<li class="chapter" data-level="8.4" data-path="Mersey_set_up.html"><a href="Mersey_set_up.html#practical-2-data"><i class="fa fa-check"></i><b>8.4</b> Data description</a></li>
<li class="chapter" data-level="8.5" data-path="Mersey_set_up.html"><a href="Mersey_set_up.html#open-rstudio-1"><i class="fa fa-check"></i><b>8.5</b> Open RStudio</a></li>
<li class="chapter" data-level="8.6" data-path="Mersey_set_up.html"><a href="Mersey_set_up.html#projects-and-scripts"><i class="fa fa-check"></i><b>8.6</b> Projects and Scripts</a>
<ul>
<li class="chapter" data-level="8.6.1" data-path="Mersey_set_up.html"><a href="Mersey_set_up.html#Existing_R_Projects"><i class="fa fa-check"></i><b>8.6.1</b> Using an existing R project</a></li>
<li class="chapter" data-level="8.6.2" data-path="Mersey_set_up.html"><a href="Mersey_set_up.html#creating-an-r-script-1"><i class="fa fa-check"></i><b>8.6.2</b> Creating an R script</a></li>
</ul></li>
<li class="chapter" data-level="8.7" data-path="Mersey_set_up.html"><a href="Mersey_set_up.html#loading-packages-1"><i class="fa fa-check"></i><b>8.7</b> Loading packages</a></li>
</ul></li>
<li class="chapter" data-level="9" data-path="mersey_three.html"><a href="mersey_three.html"><i class="fa fa-check"></i><b>9</b> Mersey III - Hydrology</a>
<ul>
<li class="chapter" data-level="9.1" data-path="mersey_three.html"><a href="mersey_three.html#task-1-flow-routing"><i class="fa fa-check"></i><b>9.1</b> Task 1: Flow routing</a>
<ul>
<li class="chapter" data-level="9.1.1" data-path="mersey_three.html"><a href="mersey_three.html#creating-a-d8-pointer"><i class="fa fa-check"></i><b>9.1.1</b> Creating a D8 pointer</a></li>
<li class="chapter" data-level="9.1.2" data-path="mersey_three.html"><a href="mersey_three.html#catchment-area"><i class="fa fa-check"></i><b>9.1.2</b> Catchment area</a></li>
</ul></li>
<li class="chapter" data-level="9.2" data-path="mersey_three.html"><a href="mersey_three.html#task-2-seed-points"><i class="fa fa-check"></i><b>9.2</b> Task 2: Seed points</a>
<ul>
<li class="chapter" data-level="9.2.1" data-path="mersey_three.html"><a href="mersey_three.html#seed-repositioning"><i class="fa fa-check"></i><b>9.2.1</b> Seed repositioning</a></li>
</ul></li>
<li class="chapter" data-level="9.3" data-path="mersey_three.html"><a href="mersey_three.html#task-3-watershed-creation"><i class="fa fa-check"></i><b>9.3</b> Task 3: Watershed creation</a></li>
</ul></li>
<li class="chapter" data-level="10" data-path="mersey_bonus.html"><a href="mersey_bonus.html"><i class="fa fa-check"></i><b>10</b> Mersey IV - Catchments</a>
<ul>
<li class="chapter" data-level="10.1" data-path="mersey_bonus.html"><a href="mersey_bonus.html#task-4-extracting-catchment-characteristics"><i class="fa fa-check"></i><b>10.1</b> Task 4: Extracting catchment characteristics</a>
<ul>
<li class="chapter" data-level="10.1.1" data-path="mersey_bonus.html"><a href="mersey_bonus.html#calculating-surface-derivatives"><i class="fa fa-check"></i><b>10.1.1</b> Calculating surface derivatives</a></li>
<li class="chapter" data-level="10.1.2" data-path="mersey_bonus.html"><a href="mersey_bonus.html#extracting-continuous-characteristics"><i class="fa fa-check"></i><b>10.1.2</b> Extracting continuous characteristics</a></li>
<li class="chapter" data-level="10.1.3" data-path="mersey_bonus.html"><a href="mersey_bonus.html#extracting-categorical-characteristics"><i class="fa fa-check"></i><b>10.1.3</b> Extracting categorical characteristics</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="11" data-path="mersey_four.html"><a href="mersey_four.html"><i class="fa fa-check"></i><b>11</b> Mersey IV - Statistical analysis</a>
<ul>
<li class="chapter" data-level="11.1" data-path="mersey_four.html"><a href="mersey_four.html#task-5-model-building"><i class="fa fa-check"></i><b>11.1</b> Task 5: Model building</a>
<ul>
<li class="chapter" data-level="11.1.1" data-path="mersey_four.html"><a href="mersey_four.html#an-introduction-to-linear-models-in-r"><i class="fa fa-check"></i><b>11.1.1</b> An introduction to linear models in R</a></li>
<li class="chapter" data-level="11.1.2" data-path="mersey_four.html"><a href="mersey_four.html#train-test"><i class="fa fa-check"></i><b>11.1.2</b> Training vs. Testing</a></li>
<li class="chapter" data-level="11.1.3" data-path="mersey_four.html"><a href="mersey_four.html#the-full-model"><i class="fa fa-check"></i><b>11.1.3</b> The full model</a></li>
<li class="chapter" data-level="11.1.4" data-path="mersey_four.html"><a href="mersey_four.html#variable-selection-strategies"><i class="fa fa-check"></i><b>11.1.4</b> Variable selection strategies</a></li>
<li class="chapter" data-level="11.1.5" data-path="mersey_four.html"><a href="mersey_four.html#lasso-in-theory"><i class="fa fa-check"></i><b>11.1.5</b> LASSO in theory</a></li>
<li class="chapter" data-level="11.1.6" data-path="10-Mersey-V.html"><a href="#cross-validation-for-%CE%BB"><i class="fa fa-check"></i><b>11.1.6</b> Cross-validation for λ</a></li>
<li class="chapter" data-level="11.1.7" data-path="mersey_four.html"><a href="mersey_four.html#lasso-in-practice"><i class="fa fa-check"></i><b>11.1.7</b> LASSO in practice</a></li>
</ul></li>
<li class="chapter" data-level="11.2" data-path="mersey_four.html"><a href="mersey_four.html#task-6-model-evaluation"><i class="fa fa-check"></i><b>11.2</b> Task 6: Model evaluation</a></li>
</ul></li>
<li class="part"><span><b>Endmatter</b></span></li>
<li class="chapter" data-level="" data-path="Hints.html"><a href="Hints.html"><i class="fa fa-check"></i>Handy Hints</a>
<ul>
<li class="chapter" data-level="" data-path="Hints.html"><a href="Hints.html#dealing-with-errors-1"><i class="fa fa-check"></i>Dealing with errors</a></li>
<li class="chapter" data-level="" data-path="Hints.html"><a href="Hints.html#whitebox-functions-vs.-the-raster-package"><i class="fa fa-check"></i>Whitebox functions vs. the <code>raster</code> package</a></li>
<li class="chapter" data-level="" data-path="Hints.html"><a href="Hints.html#r-projects"><i class="fa fa-check"></i>R Projects</a></li>
<li class="chapter" data-level="" data-path="Hints.html"><a href="Hints.html#file-paths"><i class="fa fa-check"></i>File paths</a></li>
<li class="chapter" data-level="" data-path="Hints.html"><a href="Hints.html#output-files"><i class="fa fa-check"></i>Output files</a></li>
<li class="chapter" data-level="" data-path="Hints.html"><a href="Hints.html#packages-1"><i class="fa fa-check"></i>Packages</a></li>
<li class="chapter" data-level="" data-path="Hints.html"><a href="Hints.html#code-structure"><i class="fa fa-check"></i>Code structure</a></li>
<li class="chapter" data-level="" data-path="Hints.html"><a href="Hints.html#project_repair"><i class="fa fa-check"></i>Errors with R projects and the <code>here</code> package</a></li>
<li class="chapter" data-level="" data-path="Hints.html"><a href="Hints.html#catchment-characteristics-from-categorical-data"><i class="fa fa-check"></i>Catchment characteristics from categorical data</a></li>
</ul></li>
</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./"><center><br />
Hydrological analysis in R<br />
</center></a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="mersey_four" class="section level1 hasAnchor" number="11">
<h1><span class="header-section-number">Chapter 11</span> Mersey IV - Statistical analysis<a href="mersey_four.html#mersey_four" class="anchor-section" aria-label="Anchor link to header"></a></h1>
<div id="task-5-model-building" class="section level2 hasAnchor" number="11.1">
<h2><span class="header-section-number">11.1</span> Task 5: Model building<a href="mersey_four.html#task-5-model-building" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>In this next task, we will compare the information about catchment characteristics with the water quality data collected at each of the 70 monitoring stations. To begin:</p>
<blockquote>
<p>Load the csv file created at the end of Task 4 (<code>mersey_watersheds_ea.csv</code>), saving to a new variable called <code>watersheds_df</code>:</p>
</blockquote>
<div class="sourceCode" id="cb123"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb123-1"><a href="mersey_four.html#cb123-1" tabindex="-1"></a><span class="co"># Reads completed file from csv</span></span>
<span id="cb123-2"><a href="mersey_four.html#cb123-2" tabindex="-1"></a>watersheds_df <span class="ot">&lt;-</span> <span class="fu">read.csv</span>(<span class="fu">here</span>(<span class="st">&quot;output&quot;</span>, <span class="st">&quot;practical_2&quot;</span>, <span class="st">&quot;mersey_watersheds_ea.csv&quot;</span>))</span></code></pre></div>
<p>If you have any other variables in your R environment, these can be removed using <code>rm()</code>.</p>
<p>This data frame should contain the following 10 water quality indicators for each watershed:</p>
<ul>
<li>pH: acidity/alkalinity;</li>
<li>SSC: suspended solids concentration (mg l<sup>−1</sup>);</li>
<li>Ca: calcium (mg l<sup>−1</sup>);</li>
<li>Mg: magnesium (mg l<sup>−1</sup>);</li>
<li>NH<sub>4</sub>: ammonium (mg-N l<sup>−1</sup>);</li>
<li>NO<sub>3</sub>: nitrate (mg-N l<sup>−1</sup>);</li>
<li>NO<sub>2</sub>: nitrite (mg-N l<sup>−1</sup>);</li>
<li>TON: total oxidised nitrogen (mg-N l<sup>−1</sup>);</li>
<li>PO<sub>4</sub>: phosphate (mg-P l<sup>−1</sup>);</li>
<li>Zn: zinc (μg l<sup>−1</sup>).</li>
</ul>
<p>It should also contain the continuous derivatives (e.g. average elevation) and categorical derivatives (e.g. land cover percentage) for each watershed.</p>
<p><strong>Note</strong>: some of the calculated percentages may not add up to 100%. During the reclassification of the categorical datasets (<code>land_cover</code>, <code>soils</code>, <code>bedrock</code>), we focused on the macro-classes which make up the majority of the catchment and are known to have the greatest impact of river hydrochemistry (e.g. urban areas, farmland). While other land cover categories are found within each watershed (hence <span class="math inline">\(total\)</span> <span class="math inline">\(percent &lt; 100\)</span>), these typically account for only a small percentage of the total area and have a limited effect on the river environment. These categories have been excluded to simplify the analysis.</p>
<div id="an-introduction-to-linear-models-in-r" class="section level3 hasAnchor" number="11.1.1">
<h3><span class="header-section-number">11.1.1</span> An introduction to linear models in R<a href="mersey_four.html#an-introduction-to-linear-models-in-r" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>It is now time to examine the relationships between river water quality and catchment metrics. The key model outputs that are ultimately required for the assessment are:</p>
<ol style="list-style-type: decimal">
<li><p><strong>Regression equations</strong> relating each water quality variable (dependent variable; n = 10) to the <em>important</em> catchment characteristics (independent variables; n = 16).</p></li>
<li><p>An assessment of <strong>model quality</strong>. The exact metrics / plots / tests are up to you!</p></li>
</ol>
<blockquote>
<p>Remember, you <strong>don’t</strong> have to run every code block shown below, but you can do so if it would help your understanding.</p>
</blockquote>
<blockquote>
<p>In the following instructions, I will guide you through some of the keys steps for one water quality indicator (<code>Mg</code>). You can replicate this approach and add further analysis (e.g., model evaluation) for the other nine indicators.</p>
</blockquote>
<p>The simplest way to run a linear regression in R is to use the <code>lm()</code> function (i.e., a linear model), an example of which is shown below, storing in an output called <code>model</code>:</p>
<div class="sourceCode" id="cb124"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb124-1"><a href="mersey_four.html#cb124-1" tabindex="-1"></a><span class="co"># Fit a linear model (ordinary least squares regression)</span></span>
<span id="cb124-2"><a href="mersey_four.html#cb124-2" tabindex="-1"></a>model <span class="ot">&lt;-</span> <span class="fu">lm</span>(<span class="at">formula =</span> Mg <span class="sc">~</span> average_elevation, <span class="at">data =</span> watersheds_df)</span></code></pre></div>
<p>We have defined the data frame being used (<code>data = watersheds_df</code>) and the input variables from that data frame. This is achieved by including their column names, shown here:</p>
<div class="sourceCode" id="cb125"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb125-1"><a href="mersey_four.html#cb125-1" tabindex="-1"></a><span class="fu">colnames</span>(watersheds_df)</span></code></pre></div>
<pre><code>##  [1] &quot;Seed_Point_ID&quot;          &quot;FID&quot;                    &quot;EA_ID&quot;                  &quot;Group&quot;                 
##  [5] &quot;Ph&quot;                     &quot;SSC&quot;                    &quot;Ca&quot;                     &quot;Mg&quot;                    
##  [9] &quot;NH4&quot;                    &quot;NO3&quot;                    &quot;NO2&quot;                    &quot;TON&quot;                   
## [13] &quot;PO4&quot;                    &quot;Zn&quot;                     &quot;average_elevation&quot;      &quot;average_rainfall&quot;      
## [17] &quot;average_slope&quot;          &quot;average_aspect&quot;         &quot;Arable_percent&quot;         &quot;Heath_percent&quot;         
## [21] &quot;Grassland_percent&quot;      &quot;Urban_percent&quot;          &quot;Wetland_percent&quot;        &quot;Permeable_percent&quot;     
## [25] &quot;Impermeable_percent&quot;    &quot;Gleyed_percent&quot;         &quot;Peats_percent&quot;          &quot;Sands_and_Muds_percent&quot;
## [29] &quot;Limestone_percent&quot;      &quot;Coal_percent&quot;</code></pre>
<p>Input variables in the <strong>formula</strong> are separated by <code>~</code>, where the variable to the left is the dependent variable (<code>Mg</code>) and the variable to the right is an independent variable (<code>average_elevation</code>). We can, however, include <strong>multiple</strong> independent variables to perform multiple linear regression. This is achieved as follows, where additional independent variables are separated by <code>+</code>:</p>
<div class="sourceCode" id="cb127"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb127-1"><a href="mersey_four.html#cb127-1" tabindex="-1"></a><span class="co"># Fits a linear model</span></span>
<span id="cb127-2"><a href="mersey_four.html#cb127-2" tabindex="-1"></a>model <span class="ot">&lt;-</span> <span class="fu">lm</span>(<span class="at">formula =</span> Mg <span class="sc">~</span> average_elevation <span class="sc">+</span> Grassland_percent, <span class="at">data =</span> watersheds_df)</span></code></pre></div>
<p>We can then assess the model output using the <code>summary</code> function:</p>
<div class="sourceCode" id="cb128"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb128-1"><a href="mersey_four.html#cb128-1" tabindex="-1"></a><span class="fu">summary</span>(model)</span></code></pre></div>
<pre><code>## 
## Call:
## lm(formula = Mg ~ average_elevation + Grassland_percent, data = watersheds_df)
## 
## Residuals:
##     Min      1Q  Median      3Q     Max 
## -16.055  -5.932  -2.206   1.366  59.981 
## 
## Coefficients:
##                   Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept)       30.69098    4.02921   7.617 1.18e-10 ***
## average_elevation -0.05654    0.01389  -4.070 0.000126 ***
## Grassland_percent -0.12687    0.08066  -1.573 0.120473    
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 13.97 on 67 degrees of freedom
## Multiple R-squared:  0.2964, Adjusted R-squared:  0.2754 
## F-statistic: 14.11 on 2 and 67 DF,  p-value: 7.672e-06</code></pre>
<p>For this set of independent variables, we have an R<sup>2</sup> of 0.30 (<code>Multiple R-squared: 0.2964</code>) and a model <em>p</em> value of &lt; 0.01 (<code>p-value: 7.672e-06</code>).</p>
<blockquote>
<p>What is your opinion of the model performance?</p>
</blockquote>
<p>The model coefficients for the independent variables are described above, where <code>*</code> denotes <em>p</em> values &lt; 0.05 (95% probability) and <code>**</code> denotes <em>p</em> values &lt; 0.01 (99% probability). As the coefficients are very small, they are presented in scientific notation. These can be converted to numeric (non-scientific) format using the following code:</p>
<div class="sourceCode" id="cb130"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb130-1"><a href="mersey_four.html#cb130-1" tabindex="-1"></a><span class="fu">format</span>(<span class="sc">-</span><span class="fl">2.096e-04</span>, <span class="at">scientific =</span> <span class="cn">FALSE</span>)</span></code></pre></div>
<pre><code>## [1] &quot;-0.0002096&quot;</code></pre>
<p>We can supply multiple values to the <code>format</code> function by creating a vector:</p>
<div class="sourceCode" id="cb132"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb132-1"><a href="mersey_four.html#cb132-1" tabindex="-1"></a><span class="fu">format</span>(<span class="fu">c</span>(<span class="sc">-</span><span class="fl">2.096e-04</span>, <span class="sc">-</span><span class="fl">8.358e-06</span>, ...) , <span class="at">scientific =</span> <span class="cn">FALSE</span>)</span></code></pre></div>
<blockquote>
<p>When you’re happy you understanding the formatting of the <code>lm</code> function, move on to the next section.</p>
</blockquote>
</div>
<div id="train-test" class="section level3 hasAnchor" number="11.1.2">
<h3><span class="header-section-number">11.1.2</span> Training vs. Testing<a href="mersey_four.html#train-test" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>One <strong>limitation</strong> of the above approach is that our dataframe (<code>watersheds_df</code>) contains observations from all 70 EA monitoring stations.</p>
<p>When performing statistical analysis, it is common practice to split any dataset into:</p>
<ul>
<li>a <strong>training</strong> subset, which is used to create the model(s).</li>
<li>a <strong>testing</strong> subset, which is used to evaluate the model(s).</li>
</ul>
<p>Subsetting our data in this way allows models to be evaluated more rigorously. Many models perform well “in-sample” but poorly “out-of-sample” when evaluated against independent data (i.e. the testing subset). This is commonly referred to as <strong>over-fitting</strong>.</p>
<p>Training and testing subsets are usually defined randomly, with an approximate ratio of 70:30 (although this varies). However, and to ensure reproducibility, this step has been completed for you: the <code>watersheds_df</code> dataframe contains a <code>group</code> variable denoting which monitoring sites belong to the training and testing subsets.</p>
<blockquote>
<p>Run the code above to create <code>training</code> and <code>testing</code> dataframes:</p>
</blockquote>
<div class="sourceCode" id="cb133"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb133-1"><a href="mersey_four.html#cb133-1" tabindex="-1"></a><span class="co"># Extracts training dataset, comprising 50 observations (~70%)</span></span>
<span id="cb133-2"><a href="mersey_four.html#cb133-2" tabindex="-1"></a>training <span class="ot">&lt;-</span> <span class="fu">subset</span>(watersheds_df, Group <span class="sc">==</span> <span class="st">&quot;Training&quot;</span>)</span>
<span id="cb133-3"><a href="mersey_four.html#cb133-3" tabindex="-1"></a></span>
<span id="cb133-4"><a href="mersey_four.html#cb133-4" tabindex="-1"></a><span class="co"># Extracts training dataset, comprising 20 observations (~30%)</span></span>
<span id="cb133-5"><a href="mersey_four.html#cb133-5" tabindex="-1"></a>testing <span class="ot">&lt;-</span> <span class="fu">subset</span>(watersheds_df, Group <span class="sc">==</span> <span class="st">&quot;Testing&quot;</span>) </span></code></pre></div>
<blockquote>
<p>Before you move on to the next section, can you think of any limitations of this approach?</p>
</blockquote>
<blockquote>
<p>Hints: How important is the training-testing ratio? How are training-testing subsets created?</p>
</blockquote>
</div>
<div id="the-full-model" class="section level3 hasAnchor" number="11.1.3">
<h3><span class="header-section-number">11.1.3</span> The full model<a href="mersey_four.html#the-full-model" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>An additional <strong>limitation</strong> of the above approach is that we have manually defined the independent variables of interest (<code>average_elevation + Grassland_percent</code>). For exploratory analysis, however, we may not know which are the most important variables. Perhaps there is a combination of independent variables which produces a better model fit (e.g. R<sup>2</sup> &gt; 0.30)?</p>
<p>As a first step, we could create a full model including <strong>all</strong> the <em>relevant</em> independent variables. This would include the normalised variables (e.g. <code>Arable_percent</code>, <code>Heath_percent</code>, …), but we’d want to exclude the categorical counts (e.g. <code>Arable</code>, <code>Heath</code>, … influenced by catchment size), as well as any IDs or geometry variables. In general, we are only interested in testing the continuous derivatives (column names starting with <code>average_</code>) and the normalised categorical derivatives (column names ending in <code>_percent</code>).</p>
<p>Rather than typing out the columns of interest manually, we are going to use the <code>select</code> function from the <code>dplyr</code> package to achieve this:</p>
<div class="sourceCode" id="cb134"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb134-1"><a href="mersey_four.html#cb134-1" tabindex="-1"></a><span class="co"># Creates a vector of column names, including only those which contain &quot;average&quot; or &quot;percent&quot;</span></span>
<span id="cb134-2"><a href="mersey_four.html#cb134-2" tabindex="-1"></a>factors <span class="ot">&lt;-</span> <span class="fu">colnames</span>(watersheds_df <span class="sc">%&gt;%</span> dplyr<span class="sc">::</span><span class="fu">select</span>(<span class="fu">contains</span>(<span class="fu">c</span>(<span class="st">&quot;average&quot;</span>, <span class="st">&quot;percent&quot;</span>))))</span>
<span id="cb134-3"><a href="mersey_four.html#cb134-3" tabindex="-1"></a></span>
<span id="cb134-4"><a href="mersey_four.html#cb134-4" tabindex="-1"></a><span class="co"># Prints to console</span></span>
<span id="cb134-5"><a href="mersey_four.html#cb134-5" tabindex="-1"></a>factors</span></code></pre></div>
<pre><code>##  [1] &quot;average_elevation&quot;      &quot;average_rainfall&quot;       &quot;average_slope&quot;          &quot;average_aspect&quot;        
##  [5] &quot;Arable_percent&quot;         &quot;Heath_percent&quot;          &quot;Grassland_percent&quot;      &quot;Urban_percent&quot;         
##  [9] &quot;Wetland_percent&quot;        &quot;Permeable_percent&quot;      &quot;Impermeable_percent&quot;    &quot;Gleyed_percent&quot;        
## [13] &quot;Peats_percent&quot;          &quot;Sands_and_Muds_percent&quot; &quot;Limestone_percent&quot;      &quot;Coal_percent&quot;</code></pre>
<blockquote>
<p>Run the above code. <strong>Note</strong>, the formatting of <code>dplyr::select</code> may be slightly confusing but it is necessary because there is also a <code>select</code> function in the <code>MASS</code> package. Here, we are telling R to use <code>select</code> from <code>dplyr</code>.</p>
</blockquote>
<p>Using this vector of column names, we are going to create new data frames (called <code>training_df</code> and <code>testing_df</code>) containing only the independent variables of interest for the <code>training</code> dataset:</p>
<div class="sourceCode" id="cb136"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb136-1"><a href="mersey_four.html#cb136-1" tabindex="-1"></a>training_df <span class="ot">&lt;-</span> training[factors]</span>
<span id="cb136-2"><a href="mersey_four.html#cb136-2" tabindex="-1"></a>testing_df <span class="ot">&lt;-</span> testing[factors]</span></code></pre></div>
<blockquote>
<p>Run the above code and use <code>head()</code> to inspect the results.</p>
</blockquote>
<p>To run a linear regression using these data, we need to ensure our dependent variable of interest is also present in the dataframe, which can be achieved using <code>cbind</code>. Note that we have specified <code>variable</code> as the name of the column containing the <code>Mg</code> values, but this can be changed if you desire:</p>
<div class="sourceCode" id="cb137"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb137-1"><a href="mersey_four.html#cb137-1" tabindex="-1"></a><span class="co"># Column bind (cbind) the dependent (n=1) and independent variables (n=16)</span></span>
<span id="cb137-2"><a href="mersey_four.html#cb137-2" tabindex="-1"></a>model_df <span class="ot">&lt;-</span> <span class="fu">cbind</span>(<span class="at">variable =</span> training<span class="sc">$</span>Mg, training_df)</span></code></pre></div>
<blockquote>
<p>Run the above code which creates a new dataframe (<code>model_df</code>) containing the dependent variable we want to model (<code>Mg</code>) and the full set of independent variables for our training set.</p>
</blockquote>
<blockquote>
<p>Next, run a new <code>lm()</code> model using all the independent variables, which can be acheived using the equation <code>variable ~ .</code>, and inspect the output.</p>
</blockquote>
<pre><code>## 
## Call:
## lm(formula = variable ~ ., data = model_df)
## 
## Residuals:
##     Min      1Q  Median      3Q     Max 
## -23.906  -4.577  -0.762   2.907  45.248 
## 
## Coefficients:
##                          Estimate Std. Error t value Pr(&gt;|t|)  
## (Intercept)             85.884874 612.423593   0.140   0.8893  
## average_elevation        0.073763   0.082405   0.895   0.3772  
## average_rainfall        -0.032572   0.032796  -0.993   0.3278  
## average_slope            0.959319   2.989139   0.321   0.7503  
## average_aspect          -0.056961   0.071344  -0.798   0.4303  
## Arable_percent           0.745315   0.345833   2.155   0.0385 *
## Heath_percent           -0.008754   0.459029  -0.019   0.9849  
## Grassland_percent       -0.111924   0.347421  -0.322   0.7494  
## Urban_percent            0.060574   0.366645   0.165   0.8698  
## Wetland_percent         -0.093537   0.405536  -0.231   0.8190  
## Permeable_percent       -2.510005   5.944348  -0.422   0.6756  
## Impermeable_percent     -2.682134   5.919185  -0.453   0.6534  
## Gleyed_percent          -2.306212   5.941057  -0.388   0.7004  
## Peats_percent           -2.609482   5.974192  -0.437   0.6651  
## Sands_and_Muds_percent   1.896667   1.506477   1.259   0.2169  
## Limestone_percent        1.849674   1.584516   1.167   0.2514  
## Coal_percent             1.958293   1.508695   1.298   0.2033  
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 13.95 on 33 degrees of freedom
## Multiple R-squared:  0.6147, Adjusted R-squared:  0.4279 
## F-statistic: 3.291 on 16 and 33 DF,  p-value: 0.001857</code></pre>
<blockquote>
<p><strong>Question</strong>: How has model performance changed?</p>
</blockquote>
<blockquote>
<p>Do you think adding all our independent variables to the model is a good approach?</p>
</blockquote>
<div id="problems-with-the-full-model" class="section level4 hasAnchor" number="11.1.3.1">
<h4><span class="header-section-number">11.1.3.1</span> Problems with the full model<a href="mersey_four.html#problems-with-the-full-model" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>Including all the independent variables has improved our model performance on the <code>training</code> set. <em>However</em>, there are some important issues we need to consider:</p>
<ul>
<li><p>While adding all the independent variables has increased the overall model fit (R<sup>2</sup>), we don’t know which variables are actually <strong>important</strong>. Perhaps only one or two of these have a demonstrable and/or high magnitude effect on the dependent variable? In the example above, only one coefficient is marked as significant at <span class="math inline">\(p &lt; 0.05\)</span> (<code>Arable_percent</code>).</p></li>
<li><p>In general, we prefer models with the minimum number of parameters (independent variables). These models require fewer assumptions, less intensive data collection, can be applied more confidently to new data sets/locations, and are often easier to interpret. This principle of <strong>model parsimony</strong> is based upon <a href="https://www.britannica.com/topic/Occams-razor"><em>Occam’s Razor</em></a>: “other things being equal, simpler explanations are generally better than more complex ones”.</p></li>
<li><p>Another, and perhaps more important issue, is that we not yet assessed the performance of the model on the <code>testing</code> data set. Good performance on the training set is a promising sign, but we also need to evaluate how the model performs on unseen and independent data.</p></li>
</ul>
<p>To achieve this, we can use the <code>predict()</code> function which predicts new values for <code>Mg</code> based on our model and using catchment characteristics from the <code>testing</code> set (<code>newdata = testing</code>):</p>
<div class="sourceCode" id="cb139"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb139-1"><a href="mersey_four.html#cb139-1" tabindex="-1"></a><span class="co"># Predict Mg values based upon linear model, saving to testing dataframe</span></span>
<span id="cb139-2"><a href="mersey_four.html#cb139-2" tabindex="-1"></a>testing<span class="sc">$</span>predicted_Mg <span class="ot">&lt;-</span> <span class="fu">predict</span>(linear_model, <span class="at">newdata =</span> testing)</span></code></pre></div>
<blockquote>
<p>Run the above code, which will create a new column in the <code>testing</code> dataframe called <code>predicted_Mg</code>, using our model as input (<code>linear_model</code>).</p>
</blockquote>
<blockquote>
<p>To evaluate the model performance, create a scatter plot of measured <code>Mg</code> <em>vs.</em> predicted <code>Mg</code> values, using the skills developed in the <a href="@Intro_to_R">Introduction to R</a>. I would recommend adding a 1:1 line to the plot, as follows: <code>geom_abline(intercept = 0, slope = 1, lty = "dashed")</code>. You could also add a linear regression using the measured and modelled values, although see below for important disucssion. This can be acheived using the following: <code>geom_smooth(method = "lm", se = FALSE, colour="#FF953C")</code>.</p>
</blockquote>
<p><img src="Practical_1_files/figure-html/unnamed-chunk-131-1.png" width="672" style="display: block; margin: auto;" /></p>
<blockquote>
<p>Use this plot to assess the model performance on the <code>testing</code> set. Can you see evidence of systematic and/or random error?</p>
</blockquote>
<p>While this plot allows for visual evaluation of the model, it is also useful to produce metrics for a quantitative evaluation, such as root-mean-square error (RMSE), normalised root-mean-square-error (nRMSE), or R<sup>2</sup>, which you’ve covered earlier in the unit.</p>
<p>It is also <em>tempting</em> at this stage to produce a regression between the measured and modelled values, such as the following:</p>
<div class="sourceCode" id="cb140"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb140-1"><a href="mersey_four.html#cb140-1" tabindex="-1"></a><span class="co"># Regression (measured vs. modelled)</span></span>
<span id="cb140-2"><a href="mersey_four.html#cb140-2" tabindex="-1"></a>prediction_model <span class="ot">&lt;-</span> <span class="fu">lm</span>(<span class="at">formula =</span> Mg <span class="sc">~</span> predicted_Mg, <span class="at">data =</span> testing)</span>
<span id="cb140-3"><a href="mersey_four.html#cb140-3" tabindex="-1"></a><span class="fu">summary</span>(prediction_model)</span></code></pre></div>
<pre><code>## 
## Call:
## lm(formula = Mg ~ predicted_Mg, data = testing)
## 
## Residuals:
##    Min     1Q Median     3Q    Max 
## -8.965 -4.264 -3.068  2.177 24.748 
## 
## Coefficients:
##              Estimate Std. Error t value Pr(&gt;|t|)   
## (Intercept)    8.4309     2.1783   3.870  0.00112 **
## predicted_Mg   0.2560     0.0906   2.826  0.01119 * 
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 8.145 on 18 degrees of freedom
## Multiple R-squared:  0.3073, Adjusted R-squared:  0.2688 
## F-statistic: 7.986 on 1 and 18 DF,  p-value: 0.01119</code></pre>
<p>While this looks like a sensible approach, this is actually <strong>incorrect</strong> because this is evaluating the deviations from the modelled line-of-best-fit (shown in <span class="math inline">\({\color{#FF953C}{orange}}\)</span> above), and <ins>not</ins> the 1:1 line. An easy mistake!</p>
<p>To illustrate, below is a plot of some data from Alexander et al. (<a href="https://doi.org/10.1021/acs.jcim.5b00206">2015</a>), a highly recommended paper on <span class="math inline">\(R^2\)</span>. As you can see from the plot, there is a clear correspondence between the observed and predicted values. If we run a linear regression on these data (<code>lm(formula = observed ~ predicted...</code>), then <span class="math inline">\(R^2=1\)</span> i.e., a straight line can be drawn <em>through</em> the data points.</p>
<p>This is misleading, however, because the data are far from the 1:1 line. The correct <span class="math inline">\(R^2\)</span> is actually <span class="math inline">\(-1.26\)</span>, which is very different!</p>
<pre><code>## 
## Call:
## lm(formula = observed ~ predicted, data = df)
## 
## Residuals:
##         1         2         3         4         5         6         7 
##  0.001274 -0.002371  0.001560 -0.002084  0.006710 -0.009373  0.004283 
## 
## Coefficients:
##              Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept) -0.022030   0.018586  -1.185    0.289    
## predicted    0.852532   0.002171 392.738 2.03e-12 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 0.005749 on 5 degrees of freedom
## Multiple R-squared:      1,  Adjusted R-squared:      1 
## F-statistic: 1.542e+05 on 1 and 5 DF,  p-value: 2.031e-12</code></pre>
<p><img src="Practical_1_files/figure-html/unnamed-chunk-133-1.png" width="672" style="display: block; margin: auto;" /></p>
<p>To produce the <strong>correct</strong> <span class="math inline">\(R^2\)</span>, we need to do so manually using the following equation:</p>
<p><span class="math display">\[R^2=1-\frac{RSS}{TSS}\]</span>
Here <span class="math inline">\(RSS\)</span> is the residual sum of squares i.e., deviations of predicted values (e.g., <code>predicted_Mg</code>) from actual empirical values (e.g., <code>Mg</code>), and can be calculated in R as follows:</p>
<div class="sourceCode" id="cb143"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb143-1"><a href="mersey_four.html#cb143-1" tabindex="-1"></a><span class="co"># Residual sum of squares i.e., the size of the residuals from the model </span></span>
<span id="cb143-2"><a href="mersey_four.html#cb143-2" tabindex="-1"></a>rss <span class="ot">&lt;-</span> <span class="fu">sum</span>((testing<span class="sc">$</span>Mg <span class="sc">-</span> testing<span class="sc">$</span>predicted_Mg)<span class="sc">^</span><span class="dv">2</span>)</span></code></pre></div>
<p><span class="math inline">\(TSS\)</span> refers to the total sum of squares i.e., the dispersion of the data points from the average value, or as Alexander et al. (<a href="https://doi.org/10.1021/acs.jcim.5b00206">2015</a>) summarise: “<em>the size of the residuals for a null model where all predictions are the same, i.e. the mean value.</em>”</p>
<p><span class="math inline">\(TSS\)</span> involves:</p>
<ol style="list-style-type: decimal">
<li>calculating the difference between each measured value and the mean of the measured values, for example using the <code>mean()</code> function,</li>
<li>squaring the differences,</li>
<li>calculating the total sum of the squared values.</li>
</ol>
<p>For example, if these were the measured values and the mean:</p>
<p><span class="math display">\[[5.3, 4.6,6.5,8.5,10.1]\]</span>
<span class="math display">\[mean=7.0\]</span>
the <strong>differences</strong> would be as follows:
<span class="math display">\[[-1.7,-2.4,-0.5,1.5,3.1]\]</span>
the <strong>squared differences</strong> would be:</p>
<p><span class="math display">\[[2.89, 5.76, 0.25, 2.25, 9.61]\]</span>
resulting in:</p>
<p><span class="math display">\[TSS = 20.76\]</span></p>
<blockquote>
<p>Write code to calculate <span class="math inline">\(TSS\)</span> using the guidance above, and use the <span class="math inline">\(RSS\)</span> example for assistance. If you get stuck, ask for help!</p>
</blockquote>
<p>The ratio of <span class="math inline">\(RSS\)</span> to <span class="math inline">\(TSS\)</span> accounts for the <em>unexplained</em> variation in the dependent variable that is not accounted for by the model. In turn, using <span class="math inline">\(1-\frac{RSS}{TSS}\)</span> returns our <em>explained</em> variation (<span class="math inline">\(R^2\)</span>), which for the measured-modelled <code>Mg</code> data, produces:</p>
<pre><code>## [1] -2.309345</code></pre>
<p>This has produced an unexpected <strong>negative</strong> value, similar to the example data from Alexander et al. (<a href="https://doi.org/10.1021/acs.jcim.5b00206">2015</a>) above. How can we explain this?</p>
<p>Numerically, this has occurred because <span class="math inline">\(RSS &gt; TSS\)</span> i.e., the error (residuals) in the model (<span class="math inline">\(RSS\)</span>) are greater than the variation of the observations around their mean (<span class="math inline">\(TSS\)</span>). But what does that actually mean?</p>
<p>When <span class="math inline">\(R^2&lt;0\)</span>, this means that the model predictions are worse than simply using the mean of the dependent variable (<code>Mg</code>) as a predictor i.e., a horizontal line at the <code>Mg</code> mean would have lower residuals than our predictions. Not good!</p>
<p>If <code>testing</code> R<sup>2</sup> is lower than <code>training</code> R<sup>2</sup>, we would describe our models as <strong>overfit</strong> and/or <strong>poorly generalised</strong> i.e., the model performs well on the <code>training</code> set, but poorly on the <code>testing</code> set. In most cases, there may be some overfitting, but not extreme (e.g., <code>training</code> <span class="math inline">\(R^2=0.7\)</span>, <code>testing</code> <span class="math inline">\(R^2=0.4\)</span>). In our example above, we have extreme overfitting (<span class="math inline">\(R^2&lt;0\)</span>)</p>
<p>One solution to prevent overfitting is to reduce model complexity i.e., the number of independent variables. While this will generally reduce <code>training</code> performance, this can lead to improved performance on independent data (<code>testing</code>). Moreover, by reducing the number of independent variables, we can focus on the important processes (model parsimony), can make fewer assumptions, and can more easily apply our model to new situations.</p>
<blockquote>
<p>How can we acheive this?</p>
</blockquote>
</div>
</div>
<div id="variable-selection-strategies" class="section level3 hasAnchor" number="11.1.4">
<h3><span class="header-section-number">11.1.4</span> Variable selection strategies<a href="mersey_four.html#variable-selection-strategies" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Determining which variables to include/exclude from a model is a very difficult problem, which has resulted in many different variable selection strategies. Common approaches include expert opinion and/or theory, stepwise regression, implemented in <code>MASS</code>, partial least squares (PLS) regression, implemented in <code>PLS</code>, as well as elastic net methods and ridge regression, both implemented in <code>glmnet</code>. You may want to explore some of these approaches if you use regression analysis for your dissertation.</p>
<p>We are going to use a very popular and well-respected approach, known as Least Absolute Shrinkage and Selection Operator (<strong>LASSO</strong>), implemented in <code>glmnet</code>. Published by Robert Tibshirani in <a href="https://www.jstor.org/stable/2346178">1996</a>, the original work has &gt;65,000 citations! There are lots of <a href="https://www.youtube.com/watch?v=NGf0voTMlcs&amp;t=196s&amp;ab_channel=StatQuestwithJoshStarmer">online resources</a> available to learn more about LASSO, including the original paper.</p>
<p align="center">
<a name="lasso_abstract"></a>
<img src="figures/Practical-2/lasso.png" width="60%">
</p>
</div>
<div id="lasso-in-theory" class="section level3 hasAnchor" number="11.1.5">
<h3><span class="header-section-number">11.1.5</span> LASSO in theory<a href="mersey_four.html#lasso-in-theory" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>As explored in the lecture, LASSO is slightly different to ordinary least squares (OLS) regression, which produces a model which minimises the sum of the squared residuals, as shown <a href="@fig:ols">below</a>.</p>
<p><br/></p>
<p align="center">
<a name="figure_ols"></a>
<img src="figures/Practical-2/ols-schematic.png" width="60%">
</p>
<p>In <strong>ordinary least square regression</strong>, the line of best fit minimizes the sum of the squared (vertical) residuals between the data points and the line itself</p>
<p><br/></p>
<p>While this approach produces the best fit to the <code>training</code> data, this can often result in overfitting, and poor performance on <code>testing</code> data, as demonstrated with our analysis of <code>Mg</code>.</p>
<p>Instead, LASSO minimises the sum of the squared residuals, but also adds an additional <strong>penalty</strong> term known as <strong>lambda</strong> (λ), which is applied to the slope coefficient of the model (<span class="math inline">\(λ×slope\)</span>). While OLS minimises the sum of the squared residuals, LASSO returns the model with the minimal overall error (sum of the squared residuals + <span class="math inline">\(λ×slope\)</span>).</p>
<p>The aim of this approach is to add a small amount of <strong>bias</strong> to our model. While this generally results in a worse fit for the <code>training</code> data, this often leads to improved performance on the <code>testing</code> data.</p>
<p><br/></p>
<p align="center">
<a name="figure_ols"></a>
<img src="figures/Practical-2/lasso-schematic.png" width="60%">
</p>
<p>In <strong>LASSO</strong>, an additional penalty term (λ) is used to reduce overfitting</p>
<p><br/></p>
<p>This approach is known as <em>regularisation</em>, which in effect is reducing the sensitivity of our model to the <code>training</code> data. A model that is highly tuned to the <code>training</code> data often won’t perform well in other situations. In contrast, models containing fewer variables and/or additional bias (<span class="math inline">\(λ×slope\)</span>) are often more <strong>generalisable</strong>.</p>
<p>One key aspect we haven’t discussed in depth is <strong>lambda</strong> (λ). This refers to the <strong>size of the penalty</strong> we apply to the slope coefficient i.e., how much should we penalise steeper slope coefficients in our model? Note that the shallower the slope of the model, the less sensitive it is to the <code>training</code> data.</p>
<ul>
<li><p>If λ = 0, then no penalty would be applied, and the results of LASSO would be identical to OLS.</p></li>
<li><p>As we increase λ, the slope of the model will get closer and closer to 0 (i.e., the model is very insensitive to the <code>training</code> data)</p></li>
</ul>
<p><strong>How then should we choose a suitable lambda for λ?</strong></p>
</div>
<div id="cross-validation-for-λ" class="section level3 hasAnchor" number="11.1.6">
<h3><span class="header-section-number">11.1.6</span> Cross-validation for λ<a href="#cross-validation-for-%CE%BB" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>A common approach to choose λ (and other model parameters) is known as <strong>cross-validation</strong>. There are many different methods that can be used here, such as <em>k</em>-fold cross-validation or leave-<em>one</em>-out cross-validation (LOOCV), but the underlying approach is similar and is summarised in the figure below.</p>
<p align="center">
<a name="figure_cross_validation"></a>
<img src="figures/Practical-2/cross-validation-schematic.png" width="60%">
</p>
<p>In <em>k</em>-fold <strong>cross-validation</strong>, the training set is split into <em>k</em>-folds, with one fold left out for each model run. The model performance on this fold is used to evaluate performance, as with the <code>testing</code> set.</p>
<p><br/></p>
<p>We’ve already split our data into <a href="@train-test">training-testing subsets</a>. Cross-validation repeats the process, splitting the training data into different groups (or sets or folds). For example, <strong>10-fold</strong> cross-validation would split the training data into ten folds. The model would then be trained using a dataset comprising nine of the ten folds, with the final fold left out and used for model evaluation. This process would then be repeated, leaving a different fold out for each model run. When all combinations have been tested, the final model might be the average of the <em>k</em> model runs or the best performing one.</p>
<p>One disadvantage of cross-validation is that the training data will be split <strong>randomly</strong> into different folds. If you run your analysis again, the data within each fold will be different and your model output might also differ!</p>
<p>One way to account for this is to repeat cross-validation many times (e.g., <span class="math inline">\(×100\)</span> or <span class="math inline">\(×1000\)</span>), which generally produces more stable coefficients. This is the approach we’ll use in the following sections.</p>
<blockquote>
<p>Before we move on the use LASSO in R, make sure you understand the approaches outlined above. If you can answer the following, move on!</p>
</blockquote>
<blockquote>
<p>How does LASSO differ from OLS?</p>
</blockquote>
<blockquote>
<p>What is λ?</p>
</blockquote>
<blockquote>
<p>How does cross-validation work?</p>
</blockquote>
</div>
<div id="lasso-in-practice" class="section level3 hasAnchor" number="11.1.7">
<h3><span class="header-section-number">11.1.7</span> LASSO in practice<a href="mersey_four.html#lasso-in-practice" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>In R, we can run a LASSO regression via <code>glmnet</code>, which is described in full <a href="https://glmnet.stanford.edu/articles/glmnet.html">here</a>. The main function, which confusingly is also named <code>glmnet()</code>, takes in dependent and independent variables in a similar way to <code>lm()</code>, but as vectors or matrixes, rather than data frames, as shown below.</p>
<p>One key input of <code>glmnet()</code> is the <code>alpha</code> parameter. For our analysis, we are going to keep <span class="math inline">\(alpha = 1\)</span>, which denotes that we are performing LASSO regression. The package <code>glmnet()</code> is designed to enable a more complex approach known as <em>elastic net regression</em>, published by Zou and Hastie (<a href="https://doi.org/10.1111/j.1467-9868.2005.00503.x">2005</a>). This method incorporates both LASSO and a similar technique known as <em>ridge regression</em>. While elastic net is an excellent approach, combining the strengths of both LASSO and ridge, it is much more complex.</p>
<div class="sourceCode" id="cb145"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb145-1"><a href="mersey_four.html#cb145-1" tabindex="-1"></a><span class="co"># Independent variables (x)</span></span>
<span id="cb145-2"><a href="mersey_four.html#cb145-2" tabindex="-1"></a>x <span class="ot">&lt;-</span> <span class="fu">as.matrix</span>(training_df)</span>
<span id="cb145-3"><a href="mersey_four.html#cb145-3" tabindex="-1"></a></span>
<span id="cb145-4"><a href="mersey_four.html#cb145-4" tabindex="-1"></a><span class="co"># Dependent variable (y)</span></span>
<span id="cb145-5"><a href="mersey_four.html#cb145-5" tabindex="-1"></a>y <span class="ot">&lt;-</span> training<span class="sc">$</span>Mg</span>
<span id="cb145-6"><a href="mersey_four.html#cb145-6" tabindex="-1"></a></span>
<span id="cb145-7"><a href="mersey_four.html#cb145-7" tabindex="-1"></a><span class="co"># A vanilla Lasso regression (alpha = 1)</span></span>
<span id="cb145-8"><a href="mersey_four.html#cb145-8" tabindex="-1"></a>lasso <span class="ot">&lt;-</span> <span class="fu">glmnet</span>(</span>
<span id="cb145-9"><a href="mersey_four.html#cb145-9" tabindex="-1"></a>  <span class="at">x =</span> x,</span>
<span id="cb145-10"><a href="mersey_four.html#cb145-10" tabindex="-1"></a>  <span class="at">y =</span> y,  </span>
<span id="cb145-11"><a href="mersey_four.html#cb145-11" tabindex="-1"></a>  <span class="at">alpha =</span> <span class="dv">1</span></span>
<span id="cb145-12"><a href="mersey_four.html#cb145-12" tabindex="-1"></a>)</span></code></pre></div>
<blockquote>
<p>Run the above the code and print the regression results using <code>print(lasso)</code>. This output shows a range of potential models, which vary in terms of the number of non-zero coefficients (Df) (i.e., the number of independent variables in the model), the percentage of deviance explained (%dev), and the value of λ i.e., the parameter that controls the strength of the penalty.</p>
</blockquote>
<pre><code>## 
## Call:  glmnet(x = x, y = y, alpha = 1) 
## 
##     Df  %Dev  Lambda
## 1    0  0.00 11.5300
## 2    1  6.77 10.5100
## 3    2 12.61  9.5720
## 4    2 19.30  8.7220
## 5    2 24.86  7.9470
## 6    2 29.47  7.2410
## 7    2 33.30  6.5980
## 8    2 36.47  6.0120
## 9    2 39.11  5.4780
## 10   2 41.30  4.9910
## 11   2 43.12  4.5480
## 12   2 44.63  4.1440
## 13   2 45.88  3.7750
## 14   2 46.92  3.4400
## 15   2 47.79  3.1340
## 16   2 48.51  2.8560
## 17   2 49.10  2.6020
## 18   2 49.60  2.3710
## 19   3 50.05  2.1600
## 20   4 50.49  1.9690
## 21   5 50.99  1.7940
## 22   5 51.43  1.6340
## 23   6 51.85  1.4890
## 24   6 52.30  1.3570
## 25   6 52.67  1.2360
## 26   6 52.97  1.1260
## 27   6 53.23  1.0260
## 28   7 53.61  0.9352
## 29   7 54.32  0.8521
## 30   7 54.90  0.7764
## 31   7 55.38  0.7075
## 32   7 55.78  0.6446
## 33   7 56.11  0.5873
## 34   8 56.41  0.5352
## 35   8 56.66  0.4876
## 36   8 56.87  0.4443
## 37   8 57.05  0.4048
## 38   9 57.27  0.3689
## 39   9 57.47  0.3361
## 40   9 57.64  0.3062
## 41   9 57.78  0.2790
## 42  10 57.94  0.2542
## 43  10 58.16  0.2317
## 44  10 58.33  0.2111
## 45  10 58.48  0.1923
## 46  10 58.60  0.1752
## 47  10 58.70  0.1597
## 48  12 58.79  0.1455
## 49  12 58.87  0.1326
## 50  12 58.93  0.1208
## 51  12 58.99  0.1101
## 52  12 59.03  0.1003
## 53  12 59.07  0.0914
## 54  12 59.10  0.0833
## 55  13 59.14  0.0759
## 56  13 59.16  0.0691
## 57  13 59.19  0.0630
## 58  14 59.21  0.0574
## 59  15 59.24  0.0523
## 60  14 59.37  0.0476
## 61  14 59.42  0.0434
## 62  15 59.60  0.0396
## 63  15 59.86  0.0360
## 64  15 60.08  0.0328
## 65  15 60.27  0.0299
## 66  15 60.43  0.0273
## 67  15 60.56  0.0248
## 68  15 60.66  0.0226
## 69  15 60.76  0.0206
## 70  15 60.83  0.0188
## 71  14 60.90  0.0171
## 72  14 60.95  0.0156
## 73  14 61.00  0.0142
## 74  14 61.03  0.0130
## 75  14 61.07  0.0118
## 76  14 61.09  0.0107
## 77  15 61.11  0.0098
## 78  15 61.14  0.0089
## 79  16 61.15  0.0081
## 80  16 61.17  0.0074
## 81  16 61.18  0.0068
## 82  16 61.20  0.0062
## 83  16 61.21  0.0056
## 84  16 61.22  0.0051
## 85  16 61.23  0.0047
## 86  16 61.23  0.0042
## 87  16 61.24  0.0039
## 88  16 61.25  0.0035
## 89  16 61.25  0.0032
## 90  16 61.26  0.0029
## 91  16 61.26  0.0027
## 92  16 61.26  0.0024
## 93  16 61.27  0.0022
## 94  16 61.27  0.0020
## 95  16 61.27  0.0018
## 96  16 61.27  0.0017
## 97  16 61.28  0.0015
## 98  16 61.28  0.0014
## 99  16 61.28  0.0013
## 100 16 61.28  0.0012</code></pre>
<p>There are lots of models here, with differing values for λ, so how do we pick one? This is where <strong>cross-validation</strong> comes in, splitting the data into <em>k</em>-folds, and repeating the process until we find the best value for λ.</p>
<blockquote>
<p>Run the code below to run LASSO with cross-validation, using 10-folds.</p>
</blockquote>
<div class="sourceCode" id="cb147"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb147-1"><a href="mersey_four.html#cb147-1" tabindex="-1"></a><span class="co"># Lasso regression (alpha = 1), with 10-fold cross-validation</span></span>
<span id="cb147-2"><a href="mersey_four.html#cb147-2" tabindex="-1"></a>lasso_cv <span class="ot">&lt;-</span> <span class="fu">cv.glmnet</span>(</span>
<span id="cb147-3"><a href="mersey_four.html#cb147-3" tabindex="-1"></a>  <span class="at">x =</span> x,</span>
<span id="cb147-4"><a href="mersey_four.html#cb147-4" tabindex="-1"></a>  <span class="at">y =</span> y,</span>
<span id="cb147-5"><a href="mersey_four.html#cb147-5" tabindex="-1"></a>  <span class="at">alpha =</span> <span class="dv">1</span>, </span>
<span id="cb147-6"><a href="mersey_four.html#cb147-6" tabindex="-1"></a>  <span class="at">n_folds =</span> <span class="dv">10</span></span>
<span id="cb147-7"><a href="mersey_four.html#cb147-7" tabindex="-1"></a>)</span>
<span id="cb147-8"><a href="mersey_four.html#cb147-8" tabindex="-1"></a></span>
<span id="cb147-9"><a href="mersey_four.html#cb147-9" tabindex="-1"></a><span class="co"># Plot results</span></span>
<span id="cb147-10"><a href="mersey_four.html#cb147-10" tabindex="-1"></a><span class="fu">plot</span>(lasso_cv)</span></code></pre></div>
<p><img src="Practical_1_files/figure-html/unnamed-chunk-139-1.png" width="672" style="display: block; margin: auto;" /></p>
<p>You can use <code>plot()</code> to visualise the results of cross-validation, which shows how the model performance varies with the number of non-zero coefficients and the value for λ. <strong>Note</strong>, your plot might look different to the one above, but don’t panic… Marked with dashed lines are two candidate models that the user might want to select as the final model:</p>
<ul>
<li><span class="math inline">\(λ_{min}\)</span> (<code>lambda.min</code>) i.e., the model with the minimum mean cross-validated error (y-axis)</li>
<li><span class="math inline">\(λ_{1se}\)</span> (<code>lambda.1se</code>) i.e., the model with the largest λ within 1 standard error of <span class="math inline">\(λ_{min}\)</span>.</li>
</ul>
<p><span class="math inline">\(λ_{min}\)</span> is therefore the “best” model, based upon the mean cross-validated error. However, a user might prefer to select <span class="math inline">\(λ_{1se}\)</span>. As this has a larger penalty value (λ), this will guard better against overfitting, while typically resulting in fewer independent variables.</p>
<p>This is an improvement, because we now have just two candidate models to select from, either <span class="math inline">\(λ_{min}\)</span> (minimum error, but potential for overfitting), or <span class="math inline">\(λ_{1se}\)</span> (larger error, but more parsimonious). However, there is still an issue to be solved.</p>
<blockquote>
<p>Run <code>cv.glmnet()</code> again with the same settings and keep plotting the results. What do you notice?</p>
</blockquote>
<p>If this has worked as expected, your plots and final models should have changed each time. Sometimes this difference might be quite subtle, but occasionally you will obtain a very different result. As discussed above, this is due to the <strong>random splitting</strong> of the data during cross-validation. Our relatively small dataset is quite <em>sensitive</em> to this split, whereas we might expect to see less sensitive behaviour for datasets consisting of hundreds or thousands of measurements, or where there are high magnitude or unambigious links between the dependent and independent variables.</p>
<p>To stabilise our results, we will repeat cross-validation 100 times, as shown below. This uses a <code>for</code> loop to iterate the chosen number of times, perform cross-validation, and then store the <span class="math inline">\(λ_{1se}\)</span> value for each iteration. I am using <span class="math inline">\(λ_{1se}\)</span> for model parsimony here, but you can explore the effects of using <span class="math inline">\(λ_{min}\)</span> for the assessment. For example, if using <span class="math inline">\(λ_{1se}\)</span> returns no important predictors (except for the intercept), then the model is <strong>underfit</strong>, and <span class="math inline">\(λ_{min}\)</span> might be preferable.</p>
<div class="sourceCode" id="cb148"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb148-1"><a href="mersey_four.html#cb148-1" tabindex="-1"></a><span class="co"># Number of iterations</span></span>
<span id="cb148-2"><a href="mersey_four.html#cb148-2" tabindex="-1"></a>n_repeats <span class="ot">&lt;-</span> <span class="dv">100</span></span>
<span id="cb148-3"><a href="mersey_four.html#cb148-3" tabindex="-1"></a></span>
<span id="cb148-4"><a href="mersey_four.html#cb148-4" tabindex="-1"></a><span class="co"># Empty numeric `variable` to store lambda values </span></span>
<span id="cb148-5"><a href="mersey_four.html#cb148-5" tabindex="-1"></a>lambda_values <span class="ot">&lt;-</span> <span class="fu">numeric</span>(n_repeats)</span>
<span id="cb148-6"><a href="mersey_four.html#cb148-6" tabindex="-1"></a></span>
<span id="cb148-7"><a href="mersey_four.html#cb148-7" tabindex="-1"></a><span class="co"># Iterate n_repeat times</span></span>
<span id="cb148-8"><a href="mersey_four.html#cb148-8" tabindex="-1"></a><span class="cf">for</span> (i <span class="cf">in</span> <span class="dv">1</span><span class="sc">:</span>n_repeats) {</span>
<span id="cb148-9"><a href="mersey_four.html#cb148-9" tabindex="-1"></a>  </span>
<span id="cb148-10"><a href="mersey_four.html#cb148-10" tabindex="-1"></a>  <span class="co"># Perform LASSO regression (alpha = 1), with 10-fold cross-validation</span></span>
<span id="cb148-11"><a href="mersey_four.html#cb148-11" tabindex="-1"></a>  lasso_cv <span class="ot">&lt;-</span> <span class="fu">cv.glmnet</span>(</span>
<span id="cb148-12"><a href="mersey_four.html#cb148-12" tabindex="-1"></a>    <span class="at">x =</span> x,</span>
<span id="cb148-13"><a href="mersey_four.html#cb148-13" tabindex="-1"></a>    <span class="at">y =</span> y,</span>
<span id="cb148-14"><a href="mersey_four.html#cb148-14" tabindex="-1"></a>    <span class="at">alpha =</span> <span class="dv">1</span>, <span class="at">n_folds =</span> <span class="dv">10</span></span>
<span id="cb148-15"><a href="mersey_four.html#cb148-15" tabindex="-1"></a>  )</span>
<span id="cb148-16"><a href="mersey_four.html#cb148-16" tabindex="-1"></a>  </span>
<span id="cb148-17"><a href="mersey_four.html#cb148-17" tabindex="-1"></a>  <span class="co"># Store lambda.1se</span></span>
<span id="cb148-18"><a href="mersey_four.html#cb148-18" tabindex="-1"></a>  lambda_values[i] <span class="ot">&lt;-</span> lasso_cv<span class="sc">$</span>lambda<span class="fl">.1</span>se</span>
<span id="cb148-19"><a href="mersey_four.html#cb148-19" tabindex="-1"></a>}</span></code></pre></div>
<blockquote>
<p>Run the code above and inspect the results. For example, you could plot of a histogram of the λ values using <code>hist()</code> and print out the <code>median()</code> λ.</p>
</blockquote>
<blockquote>
<p>Thinking back to earlier in the course, why would using the median λ be a better choice than mean?</p>
</blockquote>
<p>The median λ based on my repeated (n=100) 10-fold cross validation is as follows:</p>
<pre><code>## [1] 6.597705</code></pre>
<p>Your λ value should be identical or very similar. If so, it can be used to produce a final model for this dependent variable:</p>
<div class="sourceCode" id="cb150"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb150-1"><a href="mersey_four.html#cb150-1" tabindex="-1"></a><span class="co"># Final LASSO model, without cross-validation</span></span>
<span id="cb150-2"><a href="mersey_four.html#cb150-2" tabindex="-1"></a>final_model <span class="ot">&lt;-</span> <span class="fu">glmnet</span>(x, y, <span class="at">alpha =</span> <span class="dv">1</span>)</span>
<span id="cb150-3"><a href="mersey_four.html#cb150-3" tabindex="-1"></a></span>
<span id="cb150-4"><a href="mersey_four.html#cb150-4" tabindex="-1"></a><span class="co"># Print model coefficients, using our selected value for λ</span></span>
<span id="cb150-5"><a href="mersey_four.html#cb150-5" tabindex="-1"></a><span class="fu">coef</span>(final_model, <span class="at">s =</span> <span class="fu">median</span>(lambda_values))</span></code></pre></div>
<blockquote>
<p>Run the above code to run the LASSO regression and print out the model coefficients.</p>
</blockquote>
<pre><code>## 17 x 1 sparse Matrix of class &quot;dgCMatrix&quot;
##                        s=6.597705
## (Intercept)            9.62080435
## average_elevation      .         
## average_rainfall       .         
## average_slope          .         
## average_aspect         .         
## Arable_percent         0.29694731
## Heath_percent          .         
## Grassland_percent      .         
## Urban_percent          .         
## Wetland_percent        .         
## Permeable_percent      .         
## Impermeable_percent    .         
## Gleyed_percent         0.05816263
## Peats_percent          .         
## Sands_and_Muds_percent .         
## Limestone_percent      .         
## Coal_percent           .</code></pre>
<p>Our model coefficients are as follows:</p>
<ul>
<li><code>intercept</code> = 9.62080435</li>
<li><code>Arable_percent</code> = 0.29694731</li>
<li><code>Gleyed_percent</code> = 0.05816263</li>
</ul>
<p>Coefficients are important because they are used in <strong>regression equations</strong>, which can then be used for prediction.</p>
<p>The general format for a regression equation is as follows:</p>
<p><span class="math display">\[
y = a + (b_1 \cdot x_1) + (b_2 \cdot x_2) + (b_n \cdot x_n)
\]</span>
where <code>a</code> is the constant (intercept) value, and <code>b</code> is the coefficient of x.</p>
<p>For our <code>Mg</code> model above, we can define our regression equation (presented using sensible data precision) as:</p>
<p><span class="math display">\[
Mg = 9.62 + 0.30 \cdot Arable \: percent + 0.06 \cdot Gleyed \: percent
\]</span>
<strong>Well done!</strong> You have now calculated a regression which links the dependent variable (Mg) to the important independent variables, in this case the percentage of arable land cover and gleyed soils.</p>
<blockquote>
<p>For your assessment, we would like you to <strong>explain</strong> the regression results, linking to hydrological processes and literature. For example, why are <span class="math inline">\(Arable \: percent\)</span> and <span class="math inline">\(Gleyed \: percent\)</span> present in the model?</p>
</blockquote>
<blockquote>
<p>Think about specific sources of pollution, transport pathways, types of flow…</p>
</blockquote>
</div>
</div>
<div id="task-6-model-evaluation" class="section level2 hasAnchor" number="11.2">
<h2><span class="header-section-number">11.2</span> Task 6: Model evaluation<a href="mersey_four.html#task-6-model-evaluation" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>Having created a statistical model, it is necessary to evaluate its performance. Comparison plots of <strong>measured vs. modelled values</strong> are one common way to assess model quality, alongside other metrics such as root-mean-square error (RMSE), normalised root-mean-square-error (nRMSE), Q-Q plots, or histograms of model residuals. You may want to explore some of these for the assessment.</p>
<p>To predict values based on our LASSO model for the <code>testing</code> set, we can use the <code>predict()</code> function, taking the model variable (<code>final_model</code>) as the input, and using our selected λ value:</p>
<div class="sourceCode" id="cb152"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb152-1"><a href="mersey_four.html#cb152-1" tabindex="-1"></a><span class="co"># Predict Mg values based upon LASSO model and our selected λ, using &#39;testing&#39; as input</span></span>
<span id="cb152-2"><a href="mersey_four.html#cb152-2" tabindex="-1"></a>testing<span class="sc">$</span>predicted_Mg <span class="ot">&lt;-</span> <span class="fu">predict</span>(final_model, <span class="at">newx =</span> <span class="fu">as.matrix</span>(testing_df), <span class="at">s =</span> <span class="fu">median</span>(lambda_values))</span></code></pre></div>
<blockquote>
<p>Run the above code block to predict Mg concentrations in the <code>testing</code> dataset, using the LASSO model produced from the <code>training</code> dataset. Note that you can also run this process for the <code>training set</code> as well e.g., <code>predict(final_model, newx = x, s = median(lambda_values))</code>. This allows you to calculate metrics (e.g., R<sup>2</sup>) for both the training and testing set.</p>
</blockquote>
<p>Other metrics include RMSE or nRMSE (plus others introduced earlier in the course) using your own code or additional packages (e.g. <code>Metrics</code>);</p>
<p><span class="math display">\[
RMSE = \sqrt{mean(measured\:values - modelled\:values)^2}
\]</span></p>
<p>Plots of measured vs. modelled values (as well as Q-Q plots and histograms) can be created in ggplot2. Here is an example:</p>
<p><img src="Practical_1_files/figure-html/unnamed-chunk-145-1.png" width="672" style="display: block; margin: auto;" /></p>
<blockquote>
<p>Does the regression line match the 1:1 line? Is there any evidence of under- or over-prediction? Are there any outliers? What <strong>types</strong> of errors can you identify?</p>
</blockquote>
<p>You could also assess this relationship statistically, but be careful to calculate <span class="math inline">\(R^2\)</span> correctly (<span class="math inline">\(1-\frac{RSS}{TSS}\)</span>), rather than <code>lm(formula = Mg ~ predicted_Mg...</code>.</p>
<blockquote>
<p>How well does our Mg model perform on the testing dataset, based on the above graphs/statistics? Is out-of-sample performance comparable to in-sample performance?</p>
</blockquote>
<p><br/></p>
<p><strong>To finish the practical</strong> and to prepare for the assessment:</p>
<blockquote>
<p>Replicating the above approaches, calculate regression equations using LASSO for all 10 water quality indicators (NO<sub>2</sub>, pH, SSC, Ca, Mg, NH<sub>4</sub>, NO<sub>3</sub>, TON, PO<sub>4</sub>, Zn).</p>
</blockquote>
<blockquote>
<p>Evaluate the performance of the models. The exact approach is up to you, but I would encourage you to be <strong>ambitious</strong>. Some common approaches includes <span class="math inline">\(R^2\)</span> for the <code>training</code> and the <code>testing</code> sets, Q-Q plots, histograms of residuals, error metrics (e.g., <span class="math inline">\(RMSE\)</span>, <span class="math inline">\(NRMSE\)</span>).</p>
</blockquote>
<p><br/></p>
<p><strong>Advice</strong>:</p>
<ul>
<li><p>when constructing your models, think carefully about both over- and under-fitting. For example, in the <code>Mg</code> example above, I used <span class="math inline">\(λ_{1se}\)</span> to favour model parsimony. However, models can be underfit (e.g., no important predictors, except for the intercept), so in some cases <span class="math inline">\(λ_{min}\)</span> might be preferable.</p></li>
<li><p>when evaluating model performance, don’t worry if performance is not “good”, however you define this. Predicting water quality is challenging and we don’t always fully understand the links between catchment characteristics and river hydrochemistry. Moreover, if the models <em>were</em> all “good” (e.g., high <span class="math inline">\(R^2\)</span>, low <span class="math inline">\(RMSE\)</span>), you would have very little to discuss in your report!</p></li>
</ul>

</div>
</div>



            </section>

          </div>
        </div>
      </div>
<a href="mersey_bonus.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="Hints.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
  "sharing": null,
  "fontsettings": {
    "theme": "white",
    "family": "sans",
    "size": 2
  },
  "edit": {
    "link": null,
    "text": null
  },
  "history": {
    "link": null,
    "text": null
  },
  "view": {
    "link": null,
    "text": null
  },
  "download": null,
  "search": {
    "engine": "fuse",
    "options": null
  },
  "toc": {
    "collapse": "section"
  }
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.9/latest.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
